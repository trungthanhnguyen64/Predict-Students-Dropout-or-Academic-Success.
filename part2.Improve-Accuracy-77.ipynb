{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>9991</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>133.1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>14.345000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>14.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.51</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "5               2                39                  1    9991   \n",
       "6               1                 1                  1    9500   \n",
       "7               1                18                  4    9254   \n",
       "8               1                 1                  3    9238   \n",
       "9               1                 1                  1    9238   \n",
       "\n",
       "   Daytime/evening attendance  Previous qualification  \\\n",
       "0                           1                       1   \n",
       "1                           1                       1   \n",
       "2                           1                       1   \n",
       "3                           1                       1   \n",
       "4                           0                       1   \n",
       "5                           0                      19   \n",
       "6                           1                       1   \n",
       "7                           1                       1   \n",
       "8                           1                       1   \n",
       "9                           1                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "5                           133.1            1                      37   \n",
       "6                           142.0            1                      19   \n",
       "7                           119.0            1                      37   \n",
       "8                           137.0           62                       1   \n",
       "9                           138.0            1                       1   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "5                      37  ...                                    0   \n",
       "6                      38  ...                                    0   \n",
       "7                      37  ...                                    0   \n",
       "8                       1  ...                                    0   \n",
       "9                      19  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "5                                    5   \n",
       "6                                    8   \n",
       "7                                    5   \n",
       "8                                    6   \n",
       "9                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "5                                      17   \n",
       "6                                       8   \n",
       "7                                       5   \n",
       "8                                       7   \n",
       "9                                      14   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                          0.000000   \n",
       "1                                    6                         13.666667   \n",
       "2                                    0                          0.000000   \n",
       "3                                    5                         12.400000   \n",
       "4                                    6                         13.000000   \n",
       "5                                    5                         11.500000   \n",
       "6                                    8                         14.345000   \n",
       "7                                    0                          0.000000   \n",
       "8                                    6                         14.142857   \n",
       "9                                    2                         13.500000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "5                                               5               16.2   \n",
       "6                                               0               15.5   \n",
       "7                                               0               15.5   \n",
       "8                                               0               16.2   \n",
       "9                                               0                8.9   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "5             0.3 -0.92  Graduate  \n",
       "6             2.8 -4.06  Graduate  \n",
       "7             2.8 -4.06   Dropout  \n",
       "8             0.3 -0.92  Graduate  \n",
       "9             1.4  3.51   Dropout  \n",
       "\n",
       "[10 rows x 37 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#dataset import\n",
    "dataset = pd.read_csv('data.csv') #You need to change #directory accordingly\n",
    "dataset.head(10) #Return 10 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Graduate'],\n",
       "       ['Graduate'],\n",
       "       ['Dropout'],\n",
       "       ['Graduate'],\n",
       "       ['Graduate'],\n",
       "       ['Dropout'],\n",
       "       ['Enrolled'],\n",
       "       ['Graduate'],\n",
       "       ['Graduate'],\n",
       "       ['Enrolled'],\n",
       "       ['Graduate'],\n",
       "       ['Enrolled'],\n",
       "       ['Graduate'],\n",
       "       ['Graduate'],\n",
       "       ['Graduate'],\n",
       "       ['Enrolled'],\n",
       "       ['Graduate'],\n",
       "       ['Enrolled'],\n",
       "       ['Graduate'],\n",
       "       ['Enrolled'],\n",
       "       ['Enrolled'],\n",
       "       ['Graduate'],\n",
       "       ['Enrolled'],\n",
       "       ['Graduate'],\n",
       "       ['Graduate'],\n",
       "       ['Dropout'],\n",
       "       ['Dropout'],\n",
       "       ['Dropout'],\n",
       "       ['Graduate'],\n",
       "       ['Dropout']], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changing pandas dataframe to numpy array\n",
    "X = dataset.iloc[:,:36].values\n",
    "y = dataset.iloc[:,36:37].values\n",
    "y[10:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "dummy_y[10:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 36, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 12, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "125/125 [==============================] - 4s 5ms/step - loss: 0.9439 - accuracy: 0.5973 - val_loss: 0.6961 - val_accuracy: 0.7359\n",
      "Epoch 2/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7749 - accuracy: 0.6830 - val_loss: 0.6109 - val_accuracy: 0.7765\n",
      "Epoch 3/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.7104 - val_loss: 0.5730 - val_accuracy: 0.7856\n",
      "Epoch 4/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.7302 - val_loss: 0.5542 - val_accuracy: 0.7856\n",
      "Epoch 5/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.7347 - val_loss: 0.5483 - val_accuracy: 0.7878\n",
      "Epoch 6/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.7405 - val_loss: 0.5412 - val_accuracy: 0.7946\n",
      "Epoch 7/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.7388 - val_loss: 0.5369 - val_accuracy: 0.7991\n",
      "Epoch 8/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.7501 - val_loss: 0.5308 - val_accuracy: 0.8081\n",
      "Epoch 9/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.7518 - val_loss: 0.5280 - val_accuracy: 0.8014\n",
      "Epoch 10/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7481 - val_loss: 0.5251 - val_accuracy: 0.8059\n",
      "Epoch 11/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.7528 - val_loss: 0.5250 - val_accuracy: 0.8149\n",
      "Epoch 12/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7526 - val_loss: 0.5205 - val_accuracy: 0.8104\n",
      "Epoch 13/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.7631 - val_loss: 0.5202 - val_accuracy: 0.8126\n",
      "Epoch 14/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7584 - val_loss: 0.5161 - val_accuracy: 0.8104\n",
      "Epoch 15/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7644 - val_loss: 0.5165 - val_accuracy: 0.8126\n",
      "Epoch 16/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7596 - val_loss: 0.5125 - val_accuracy: 0.8104\n",
      "Epoch 17/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7717 - val_loss: 0.5113 - val_accuracy: 0.8104\n",
      "Epoch 18/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7666 - val_loss: 0.5108 - val_accuracy: 0.8081\n",
      "Epoch 19/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7702 - val_loss: 0.5078 - val_accuracy: 0.7991\n",
      "Epoch 20/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7712 - val_loss: 0.5059 - val_accuracy: 0.8126\n",
      "Epoch 21/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7687 - val_loss: 0.5022 - val_accuracy: 0.8149\n",
      "Epoch 22/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7684 - val_loss: 0.5044 - val_accuracy: 0.8149\n",
      "Epoch 23/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7687 - val_loss: 0.5051 - val_accuracy: 0.8104\n",
      "Epoch 24/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7752 - val_loss: 0.5049 - val_accuracy: 0.8104\n",
      "Epoch 25/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7719 - val_loss: 0.5048 - val_accuracy: 0.8036\n",
      "Epoch 26/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7729 - val_loss: 0.5050 - val_accuracy: 0.8126\n",
      "Epoch 27/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7747 - val_loss: 0.5026 - val_accuracy: 0.7991\n",
      "Epoch 28/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7732 - val_loss: 0.4988 - val_accuracy: 0.8059\n",
      "Epoch 29/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7847 - val_loss: 0.4992 - val_accuracy: 0.8104\n",
      "Epoch 30/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7767 - val_loss: 0.5035 - val_accuracy: 0.8104\n",
      "Epoch 31/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7830 - val_loss: 0.4989 - val_accuracy: 0.8014\n",
      "Epoch 32/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7787 - val_loss: 0.4983 - val_accuracy: 0.8059\n",
      "Epoch 33/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7749 - val_loss: 0.5005 - val_accuracy: 0.8014\n",
      "Epoch 34/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7797 - val_loss: 0.4991 - val_accuracy: 0.7991\n",
      "Epoch 35/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7779 - val_loss: 0.4997 - val_accuracy: 0.8014\n",
      "Epoch 36/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7837 - val_loss: 0.4993 - val_accuracy: 0.8014\n",
      "Epoch 37/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7787 - val_loss: 0.5001 - val_accuracy: 0.7968\n",
      "Epoch 38/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7827 - val_loss: 0.4984 - val_accuracy: 0.8104\n",
      "Epoch 39/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7835 - val_loss: 0.4952 - val_accuracy: 0.8059\n",
      "Epoch 40/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7822 - val_loss: 0.4965 - val_accuracy: 0.8104\n",
      "Epoch 41/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7822 - val_loss: 0.4981 - val_accuracy: 0.8059\n",
      "Epoch 42/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7842 - val_loss: 0.4945 - val_accuracy: 0.8081\n",
      "Epoch 43/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7867 - val_loss: 0.4991 - val_accuracy: 0.8172\n",
      "Epoch 44/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7842 - val_loss: 0.4969 - val_accuracy: 0.8104\n",
      "Epoch 45/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7850 - val_loss: 0.4957 - val_accuracy: 0.8104\n",
      "Epoch 46/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7757 - val_loss: 0.4920 - val_accuracy: 0.8172\n",
      "Epoch 47/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7900 - val_loss: 0.4975 - val_accuracy: 0.8036\n",
      "Epoch 48/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7795 - val_loss: 0.4929 - val_accuracy: 0.8104\n",
      "Epoch 49/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7800 - val_loss: 0.4947 - val_accuracy: 0.8036\n",
      "Epoch 50/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7835 - val_loss: 0.4943 - val_accuracy: 0.8126\n",
      "Epoch 51/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7812 - val_loss: 0.4912 - val_accuracy: 0.8104\n",
      "Epoch 52/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7840 - val_loss: 0.4922 - val_accuracy: 0.8104\n",
      "Epoch 53/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7885 - val_loss: 0.4987 - val_accuracy: 0.8081\n",
      "Epoch 54/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7822 - val_loss: 0.4925 - val_accuracy: 0.8059\n",
      "Epoch 55/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7860 - val_loss: 0.4938 - val_accuracy: 0.8172\n",
      "Epoch 56/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7842 - val_loss: 0.4950 - val_accuracy: 0.8081\n",
      "Epoch 57/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7915 - val_loss: 0.4976 - val_accuracy: 0.8149\n",
      "Epoch 58/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7920 - val_loss: 0.4981 - val_accuracy: 0.8081\n",
      "Epoch 59/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7925 - val_loss: 0.4986 - val_accuracy: 0.8036\n",
      "Epoch 60/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7837 - val_loss: 0.4948 - val_accuracy: 0.8172\n",
      "Epoch 61/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7918 - val_loss: 0.4903 - val_accuracy: 0.8149\n",
      "Epoch 62/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7865 - val_loss: 0.4903 - val_accuracy: 0.8194\n",
      "Epoch 63/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7915 - val_loss: 0.4892 - val_accuracy: 0.8104\n",
      "Epoch 64/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7938 - val_loss: 0.4973 - val_accuracy: 0.8059\n",
      "Epoch 65/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7872 - val_loss: 0.4987 - val_accuracy: 0.8081\n",
      "Epoch 66/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7908 - val_loss: 0.5002 - val_accuracy: 0.8149\n",
      "Epoch 67/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7925 - val_loss: 0.5029 - val_accuracy: 0.8149\n",
      "Epoch 68/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7945 - val_loss: 0.4994 - val_accuracy: 0.8081\n",
      "Epoch 69/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7958 - val_loss: 0.4980 - val_accuracy: 0.8081\n",
      "Epoch 70/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7925 - val_loss: 0.4896 - val_accuracy: 0.8081\n",
      "Epoch 71/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7935 - val_loss: 0.4955 - val_accuracy: 0.8149\n",
      "Epoch 72/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7990 - val_loss: 0.4944 - val_accuracy: 0.8126\n",
      "Epoch 73/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7825 - val_loss: 0.4960 - val_accuracy: 0.8126\n",
      "Epoch 74/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7980 - val_loss: 0.5005 - val_accuracy: 0.8059\n",
      "Epoch 75/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7963 - val_loss: 0.4995 - val_accuracy: 0.8104\n",
      "Epoch 76/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7950 - val_loss: 0.5021 - val_accuracy: 0.8104\n",
      "Epoch 77/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7945 - val_loss: 0.4971 - val_accuracy: 0.8059\n",
      "Epoch 78/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7953 - val_loss: 0.4961 - val_accuracy: 0.8059\n",
      "Epoch 79/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7923 - val_loss: 0.4984 - val_accuracy: 0.8081\n",
      "Epoch 80/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7933 - val_loss: 0.4948 - val_accuracy: 0.8126\n",
      "Epoch 81/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7978 - val_loss: 0.4982 - val_accuracy: 0.8126\n",
      "Epoch 82/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7923 - val_loss: 0.4978 - val_accuracy: 0.8036\n",
      "Epoch 83/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7970 - val_loss: 0.4994 - val_accuracy: 0.8059\n",
      "Epoch 84/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7990 - val_loss: 0.5021 - val_accuracy: 0.8149\n",
      "Epoch 85/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7990 - val_loss: 0.4987 - val_accuracy: 0.8126\n",
      "Epoch 86/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7973 - val_loss: 0.5032 - val_accuracy: 0.8104\n",
      "Epoch 87/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7965 - val_loss: 0.4989 - val_accuracy: 0.8104\n",
      "Epoch 88/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7940 - val_loss: 0.5022 - val_accuracy: 0.8104\n",
      "Epoch 89/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7913 - val_loss: 0.5006 - val_accuracy: 0.8081\n",
      "Epoch 90/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7948 - val_loss: 0.5019 - val_accuracy: 0.8081\n",
      "Epoch 91/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7933 - val_loss: 0.4986 - val_accuracy: 0.8126\n",
      "Epoch 92/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8033 - val_loss: 0.5013 - val_accuracy: 0.8149\n",
      "Epoch 93/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7928 - val_loss: 0.5024 - val_accuracy: 0.8126\n",
      "Epoch 94/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8028 - val_loss: 0.4965 - val_accuracy: 0.8081\n",
      "Epoch 95/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7988 - val_loss: 0.4979 - val_accuracy: 0.8104\n",
      "Epoch 96/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8003 - val_loss: 0.4984 - val_accuracy: 0.8081\n",
      "Epoch 97/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8021 - val_loss: 0.4970 - val_accuracy: 0.8059\n",
      "Epoch 98/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7995 - val_loss: 0.4935 - val_accuracy: 0.8036\n",
      "Epoch 99/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8021 - val_loss: 0.4909 - val_accuracy: 0.8126\n",
      "Epoch 100/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7990 - val_loss: 0.4930 - val_accuracy: 0.8149\n",
      "Epoch 101/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7965 - val_loss: 0.4952 - val_accuracy: 0.8194\n",
      "Epoch 102/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.8048 - val_loss: 0.4968 - val_accuracy: 0.8126\n",
      "Epoch 103/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8018 - val_loss: 0.4959 - val_accuracy: 0.8172\n",
      "Epoch 104/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7993 - val_loss: 0.4985 - val_accuracy: 0.8104\n",
      "Epoch 105/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7995 - val_loss: 0.4974 - val_accuracy: 0.8104\n",
      "Epoch 106/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7948 - val_loss: 0.4896 - val_accuracy: 0.8172\n",
      "Epoch 107/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8028 - val_loss: 0.4987 - val_accuracy: 0.8036\n",
      "Epoch 108/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8003 - val_loss: 0.4979 - val_accuracy: 0.8104\n",
      "Epoch 109/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8046 - val_loss: 0.5008 - val_accuracy: 0.8104\n",
      "Epoch 110/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8061 - val_loss: 0.4988 - val_accuracy: 0.8172\n",
      "Epoch 111/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7940 - val_loss: 0.4937 - val_accuracy: 0.8172\n",
      "Epoch 112/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.8043 - val_loss: 0.4942 - val_accuracy: 0.8126\n",
      "Epoch 113/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8033 - val_loss: 0.4933 - val_accuracy: 0.8194\n",
      "Epoch 114/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8061 - val_loss: 0.4999 - val_accuracy: 0.8126\n",
      "Epoch 115/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8046 - val_loss: 0.4962 - val_accuracy: 0.8036\n",
      "Epoch 116/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8051 - val_loss: 0.5032 - val_accuracy: 0.8081\n",
      "Epoch 117/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8081 - val_loss: 0.5122 - val_accuracy: 0.8149\n",
      "Epoch 118/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.8149\n",
      "Epoch 119/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8078 - val_loss: 0.5066 - val_accuracy: 0.8104\n",
      "Epoch 120/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8106 - val_loss: 0.4982 - val_accuracy: 0.8194\n",
      "Epoch 121/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8028 - val_loss: 0.5015 - val_accuracy: 0.8149\n",
      "Epoch 122/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8033 - val_loss: 0.5024 - val_accuracy: 0.8104\n",
      "Epoch 123/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8018 - val_loss: 0.5077 - val_accuracy: 0.8126\n",
      "Epoch 124/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8018 - val_loss: 0.4954 - val_accuracy: 0.8104\n",
      "Epoch 125/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8058 - val_loss: 0.5025 - val_accuracy: 0.8104\n",
      "Epoch 126/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7993 - val_loss: 0.5064 - val_accuracy: 0.8172\n",
      "Epoch 127/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8048 - val_loss: 0.5043 - val_accuracy: 0.8104\n",
      "Epoch 128/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8058 - val_loss: 0.4989 - val_accuracy: 0.8126\n",
      "Epoch 129/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8103 - val_loss: 0.4977 - val_accuracy: 0.8172\n",
      "Epoch 130/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.8076 - val_loss: 0.4976 - val_accuracy: 0.8172\n",
      "Epoch 131/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8068 - val_loss: 0.5035 - val_accuracy: 0.8172\n",
      "Epoch 132/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8071 - val_loss: 0.5064 - val_accuracy: 0.8149\n",
      "Epoch 133/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8023 - val_loss: 0.4993 - val_accuracy: 0.8126\n",
      "Epoch 134/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8056 - val_loss: 0.5063 - val_accuracy: 0.8126\n",
      "Epoch 135/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8018 - val_loss: 0.5024 - val_accuracy: 0.8217\n",
      "Epoch 136/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8136 - val_loss: 0.5043 - val_accuracy: 0.8172\n",
      "Epoch 137/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8028 - val_loss: 0.5004 - val_accuracy: 0.8126\n",
      "Epoch 138/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8103 - val_loss: 0.5026 - val_accuracy: 0.8172\n",
      "Epoch 139/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8033 - val_loss: 0.5136 - val_accuracy: 0.8194\n",
      "Epoch 140/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8061 - val_loss: 0.5076 - val_accuracy: 0.8284\n",
      "Epoch 141/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8066 - val_loss: 0.5045 - val_accuracy: 0.8217\n",
      "Epoch 142/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8073 - val_loss: 0.5140 - val_accuracy: 0.8284\n",
      "Epoch 143/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.8056 - val_loss: 0.5116 - val_accuracy: 0.8194\n",
      "Epoch 144/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8041 - val_loss: 0.5126 - val_accuracy: 0.8172\n",
      "Epoch 145/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8066 - val_loss: 0.5150 - val_accuracy: 0.8172\n",
      "Epoch 146/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8013 - val_loss: 0.5158 - val_accuracy: 0.8172\n",
      "Epoch 147/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8096 - val_loss: 0.5096 - val_accuracy: 0.8262\n",
      "Epoch 148/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8144 - val_loss: 0.5130 - val_accuracy: 0.8217\n",
      "Epoch 149/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8043 - val_loss: 0.5171 - val_accuracy: 0.8172\n",
      "Epoch 150/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8056 - val_loss: 0.5142 - val_accuracy: 0.8307\n",
      "Epoch 151/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8149 - val_loss: 0.5138 - val_accuracy: 0.8217\n",
      "Epoch 152/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8131 - val_loss: 0.5138 - val_accuracy: 0.8194\n",
      "Epoch 153/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8061 - val_loss: 0.5076 - val_accuracy: 0.8262\n",
      "Epoch 154/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8109 - val_loss: 0.5131 - val_accuracy: 0.8262\n",
      "Epoch 155/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.8103 - val_loss: 0.5129 - val_accuracy: 0.8194\n",
      "Epoch 156/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8156 - val_loss: 0.5102 - val_accuracy: 0.8149\n",
      "Epoch 157/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8093 - val_loss: 0.5117 - val_accuracy: 0.8217\n",
      "Epoch 158/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8061 - val_loss: 0.5134 - val_accuracy: 0.8239\n",
      "Epoch 159/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8066 - val_loss: 0.5057 - val_accuracy: 0.8149\n",
      "Epoch 160/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8161 - val_loss: 0.5163 - val_accuracy: 0.8149\n",
      "Epoch 161/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8103 - val_loss: 0.5105 - val_accuracy: 0.8172\n",
      "Epoch 162/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8063 - val_loss: 0.5057 - val_accuracy: 0.8239\n",
      "Epoch 163/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8119 - val_loss: 0.5109 - val_accuracy: 0.8217\n",
      "Epoch 164/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.8151 - val_loss: 0.5107 - val_accuracy: 0.8262\n",
      "Epoch 165/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.8161 - val_loss: 0.5151 - val_accuracy: 0.8194\n",
      "Epoch 166/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8214 - val_loss: 0.5117 - val_accuracy: 0.8239\n",
      "Epoch 167/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8083 - val_loss: 0.5137 - val_accuracy: 0.8239\n",
      "Epoch 168/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8093 - val_loss: 0.5256 - val_accuracy: 0.8217\n",
      "Epoch 169/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8141 - val_loss: 0.5189 - val_accuracy: 0.8284\n",
      "Epoch 170/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8131 - val_loss: 0.5214 - val_accuracy: 0.8262\n",
      "Epoch 171/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.8131 - val_loss: 0.5264 - val_accuracy: 0.8262\n",
      "Epoch 172/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8116 - val_loss: 0.5178 - val_accuracy: 0.8194\n",
      "Epoch 173/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8129 - val_loss: 0.5148 - val_accuracy: 0.8262\n",
      "Epoch 174/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8176 - val_loss: 0.5120 - val_accuracy: 0.8262\n",
      "Epoch 175/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8093 - val_loss: 0.5175 - val_accuracy: 0.8239\n",
      "Epoch 176/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8121 - val_loss: 0.5199 - val_accuracy: 0.8307\n",
      "Epoch 177/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8174 - val_loss: 0.5151 - val_accuracy: 0.8239\n",
      "Epoch 178/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8114 - val_loss: 0.5245 - val_accuracy: 0.8284\n",
      "Epoch 179/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8086 - val_loss: 0.5158 - val_accuracy: 0.8284\n",
      "Epoch 180/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8134 - val_loss: 0.5109 - val_accuracy: 0.8307\n",
      "Epoch 181/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8136 - val_loss: 0.5083 - val_accuracy: 0.8330\n",
      "Epoch 182/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8093 - val_loss: 0.5132 - val_accuracy: 0.8239\n",
      "Epoch 183/600\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.4576 - accuracy: 0.8111 - val_loss: 0.5117 - val_accuracy: 0.8284\n",
      "Epoch 184/600\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.8136 - val_loss: 0.5114 - val_accuracy: 0.8239\n",
      "Epoch 185/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8169 - val_loss: 0.5129 - val_accuracy: 0.8307\n",
      "Epoch 186/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.8088 - val_loss: 0.5090 - val_accuracy: 0.8352\n",
      "Epoch 187/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8151 - val_loss: 0.5078 - val_accuracy: 0.8217\n",
      "Epoch 188/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8121 - val_loss: 0.5126 - val_accuracy: 0.8262\n",
      "Epoch 189/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8154 - val_loss: 0.5056 - val_accuracy: 0.8307\n",
      "Epoch 190/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8129 - val_loss: 0.4993 - val_accuracy: 0.8307\n",
      "Epoch 191/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8134 - val_loss: 0.5034 - val_accuracy: 0.8352\n",
      "Epoch 192/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.8224 - val_loss: 0.5042 - val_accuracy: 0.8284\n",
      "Epoch 193/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.8174 - val_loss: 0.5031 - val_accuracy: 0.8262\n",
      "Epoch 194/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8154 - val_loss: 0.4985 - val_accuracy: 0.8284\n",
      "Epoch 195/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8189 - val_loss: 0.5014 - val_accuracy: 0.8239\n",
      "Epoch 196/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8096 - val_loss: 0.5100 - val_accuracy: 0.8307\n",
      "Epoch 197/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8174 - val_loss: 0.5174 - val_accuracy: 0.8262\n",
      "Epoch 198/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8156 - val_loss: 0.5080 - val_accuracy: 0.8194\n",
      "Epoch 199/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8164 - val_loss: 0.5133 - val_accuracy: 0.8217\n",
      "Epoch 200/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.8134 - val_loss: 0.5089 - val_accuracy: 0.8194\n",
      "Epoch 201/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.8111 - val_loss: 0.5153 - val_accuracy: 0.8262\n",
      "Epoch 202/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.8116 - val_loss: 0.5103 - val_accuracy: 0.8239\n",
      "Epoch 203/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8144 - val_loss: 0.5123 - val_accuracy: 0.8239\n",
      "Epoch 204/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8209 - val_loss: 0.5188 - val_accuracy: 0.8194\n",
      "Epoch 205/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8209 - val_loss: 0.5166 - val_accuracy: 0.8239\n",
      "Epoch 206/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8181 - val_loss: 0.5174 - val_accuracy: 0.8262\n",
      "Epoch 207/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8121 - val_loss: 0.5171 - val_accuracy: 0.8239\n",
      "Epoch 208/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8176 - val_loss: 0.5145 - val_accuracy: 0.8307\n",
      "Epoch 209/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8078 - val_loss: 0.5167 - val_accuracy: 0.8194\n",
      "Epoch 210/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8166 - val_loss: 0.5158 - val_accuracy: 0.8194\n",
      "Epoch 211/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8159 - val_loss: 0.5206 - val_accuracy: 0.8239\n",
      "Epoch 212/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8149 - val_loss: 0.5256 - val_accuracy: 0.8217\n",
      "Epoch 213/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8086 - val_loss: 0.5197 - val_accuracy: 0.8239\n",
      "Epoch 214/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8179 - val_loss: 0.5211 - val_accuracy: 0.8194\n",
      "Epoch 215/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8171 - val_loss: 0.5125 - val_accuracy: 0.8217\n",
      "Epoch 216/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8234 - val_loss: 0.5289 - val_accuracy: 0.8172\n",
      "Epoch 217/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8098 - val_loss: 0.5325 - val_accuracy: 0.8217\n",
      "Epoch 218/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8237 - val_loss: 0.5304 - val_accuracy: 0.8149\n",
      "Epoch 219/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8237 - val_loss: 0.5203 - val_accuracy: 0.8172\n",
      "Epoch 220/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8141 - val_loss: 0.5197 - val_accuracy: 0.8217\n",
      "Epoch 221/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8229 - val_loss: 0.5217 - val_accuracy: 0.8149\n",
      "Epoch 222/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8164 - val_loss: 0.5330 - val_accuracy: 0.8262\n",
      "Epoch 223/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8212 - val_loss: 0.5309 - val_accuracy: 0.8172\n",
      "Epoch 224/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8181 - val_loss: 0.5264 - val_accuracy: 0.8217\n",
      "Epoch 225/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.8179 - val_loss: 0.5239 - val_accuracy: 0.8172\n",
      "Epoch 226/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8166 - val_loss: 0.5294 - val_accuracy: 0.8239\n",
      "Epoch 227/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8212 - val_loss: 0.5307 - val_accuracy: 0.8149\n",
      "Epoch 228/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8212 - val_loss: 0.5320 - val_accuracy: 0.8172\n",
      "Epoch 229/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8164 - val_loss: 0.5255 - val_accuracy: 0.8172\n",
      "Epoch 230/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.8181 - val_loss: 0.5288 - val_accuracy: 0.8104\n",
      "Epoch 231/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8201 - val_loss: 0.5233 - val_accuracy: 0.8172\n",
      "Epoch 232/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8116 - val_loss: 0.5305 - val_accuracy: 0.8126\n",
      "Epoch 233/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8194 - val_loss: 0.5128 - val_accuracy: 0.8172\n",
      "Epoch 234/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8174 - val_loss: 0.5068 - val_accuracy: 0.8239\n",
      "Epoch 235/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8224 - val_loss: 0.5214 - val_accuracy: 0.8217\n",
      "Epoch 236/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8217 - val_loss: 0.5167 - val_accuracy: 0.8194\n",
      "Epoch 237/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.8161 - val_loss: 0.5237 - val_accuracy: 0.8194\n",
      "Epoch 238/600\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.4460 - accuracy: 0.8139 - val_loss: 0.5200 - val_accuracy: 0.8262\n",
      "Epoch 239/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8209 - val_loss: 0.5226 - val_accuracy: 0.8194\n",
      "Epoch 240/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8229 - val_loss: 0.5251 - val_accuracy: 0.8194\n",
      "Epoch 241/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8174 - val_loss: 0.5314 - val_accuracy: 0.8172\n",
      "Epoch 242/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.8206 - val_loss: 0.5420 - val_accuracy: 0.8149\n",
      "Epoch 243/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8222 - val_loss: 0.5301 - val_accuracy: 0.8081\n",
      "Epoch 244/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.8227 - val_loss: 0.5209 - val_accuracy: 0.8172\n",
      "Epoch 245/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8144 - val_loss: 0.5332 - val_accuracy: 0.8126\n",
      "Epoch 246/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8186 - val_loss: 0.5257 - val_accuracy: 0.8149\n",
      "Epoch 247/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.8212 - val_loss: 0.5317 - val_accuracy: 0.8149\n",
      "Epoch 248/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8194 - val_loss: 0.5322 - val_accuracy: 0.8126\n",
      "Epoch 249/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8161 - val_loss: 0.5431 - val_accuracy: 0.8149\n",
      "Epoch 250/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8227 - val_loss: 0.5366 - val_accuracy: 0.8172\n",
      "Epoch 251/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8209 - val_loss: 0.5330 - val_accuracy: 0.8172\n",
      "Epoch 252/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8252 - val_loss: 0.5383 - val_accuracy: 0.8217\n",
      "Epoch 253/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8282 - val_loss: 0.5424 - val_accuracy: 0.8194\n",
      "Epoch 254/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8159 - val_loss: 0.5480 - val_accuracy: 0.8149\n",
      "Epoch 255/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8179 - val_loss: 0.5392 - val_accuracy: 0.8172\n",
      "Epoch 256/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8196 - val_loss: 0.5456 - val_accuracy: 0.8149\n",
      "Epoch 257/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8262 - val_loss: 0.5485 - val_accuracy: 0.8126\n",
      "Epoch 258/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8229 - val_loss: 0.5466 - val_accuracy: 0.8126\n",
      "Epoch 259/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8239 - val_loss: 0.5491 - val_accuracy: 0.8104\n",
      "Epoch 260/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8229 - val_loss: 0.5434 - val_accuracy: 0.8172\n",
      "Epoch 261/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8274 - val_loss: 0.5329 - val_accuracy: 0.8149\n",
      "Epoch 262/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8209 - val_loss: 0.5378 - val_accuracy: 0.8149\n",
      "Epoch 263/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8219 - val_loss: 0.5480 - val_accuracy: 0.8149\n",
      "Epoch 264/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8232 - val_loss: 0.5541 - val_accuracy: 0.8172\n",
      "Epoch 265/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.8201 - val_loss: 0.5415 - val_accuracy: 0.8081\n",
      "Epoch 266/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8191 - val_loss: 0.5379 - val_accuracy: 0.8149\n",
      "Epoch 267/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8287 - val_loss: 0.5424 - val_accuracy: 0.8172\n",
      "Epoch 268/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8171 - val_loss: 0.5350 - val_accuracy: 0.8194\n",
      "Epoch 269/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8257 - val_loss: 0.5408 - val_accuracy: 0.8081\n",
      "Epoch 270/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.8206 - val_loss: 0.5371 - val_accuracy: 0.8149\n",
      "Epoch 271/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8176 - val_loss: 0.5510 - val_accuracy: 0.8194\n",
      "Epoch 272/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8156 - val_loss: 0.5379 - val_accuracy: 0.8172\n",
      "Epoch 273/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8247 - val_loss: 0.5537 - val_accuracy: 0.8149\n",
      "Epoch 274/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8186 - val_loss: 0.5355 - val_accuracy: 0.8104\n",
      "Epoch 275/600\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8244 - val_loss: 0.5403 - val_accuracy: 0.8059\n",
      "Epoch 276/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8212 - val_loss: 0.5450 - val_accuracy: 0.8081\n",
      "Epoch 277/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8209 - val_loss: 0.5301 - val_accuracy: 0.8149\n",
      "Epoch 278/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8232 - val_loss: 0.5353 - val_accuracy: 0.8149\n",
      "Epoch 279/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.8302 - val_loss: 0.5399 - val_accuracy: 0.8126\n",
      "Epoch 280/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8189 - val_loss: 0.5409 - val_accuracy: 0.8059\n",
      "Epoch 281/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8227 - val_loss: 0.5364 - val_accuracy: 0.8104\n",
      "Epoch 282/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8222 - val_loss: 0.5463 - val_accuracy: 0.8059\n",
      "Epoch 283/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8232 - val_loss: 0.5475 - val_accuracy: 0.8014\n",
      "Epoch 284/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8234 - val_loss: 0.5476 - val_accuracy: 0.8081\n",
      "Epoch 285/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8254 - val_loss: 0.5420 - val_accuracy: 0.8059\n",
      "Epoch 286/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8287 - val_loss: 0.5529 - val_accuracy: 0.8126\n",
      "Epoch 287/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8269 - val_loss: 0.5519 - val_accuracy: 0.8081\n",
      "Epoch 288/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8209 - val_loss: 0.5463 - val_accuracy: 0.8104\n",
      "Epoch 289/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8237 - val_loss: 0.5569 - val_accuracy: 0.8036\n",
      "Epoch 290/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8299 - val_loss: 0.5606 - val_accuracy: 0.8014\n",
      "Epoch 291/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8274 - val_loss: 0.5565 - val_accuracy: 0.8036\n",
      "Epoch 292/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8206 - val_loss: 0.5532 - val_accuracy: 0.8081\n",
      "Epoch 293/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8222 - val_loss: 0.5543 - val_accuracy: 0.8014\n",
      "Epoch 294/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8222 - val_loss: 0.5587 - val_accuracy: 0.8081\n",
      "Epoch 295/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8257 - val_loss: 0.5503 - val_accuracy: 0.8081\n",
      "Epoch 296/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8272 - val_loss: 0.5509 - val_accuracy: 0.8126\n",
      "Epoch 297/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8242 - val_loss: 0.5522 - val_accuracy: 0.8126\n",
      "Epoch 298/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8242 - val_loss: 0.5462 - val_accuracy: 0.8149\n",
      "Epoch 299/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8287 - val_loss: 0.5434 - val_accuracy: 0.8104\n",
      "Epoch 300/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8277 - val_loss: 0.5538 - val_accuracy: 0.8126\n",
      "Epoch 301/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8222 - val_loss: 0.5559 - val_accuracy: 0.8104\n",
      "Epoch 302/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8277 - val_loss: 0.5460 - val_accuracy: 0.8036\n",
      "Epoch 303/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8222 - val_loss: 0.5523 - val_accuracy: 0.8059\n",
      "Epoch 304/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.8214 - val_loss: 0.5474 - val_accuracy: 0.8126\n",
      "Epoch 305/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8242 - val_loss: 0.5498 - val_accuracy: 0.8126\n",
      "Epoch 306/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8234 - val_loss: 0.5551 - val_accuracy: 0.8104\n",
      "Epoch 307/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8272 - val_loss: 0.5603 - val_accuracy: 0.7991\n",
      "Epoch 308/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8282 - val_loss: 0.5612 - val_accuracy: 0.8126\n",
      "Epoch 309/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8262 - val_loss: 0.5610 - val_accuracy: 0.8014\n",
      "Epoch 310/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8294 - val_loss: 0.5601 - val_accuracy: 0.8081\n",
      "Epoch 311/600\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8282 - val_loss: 0.5621 - val_accuracy: 0.8081\n",
      "Epoch 312/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8252 - val_loss: 0.5587 - val_accuracy: 0.8104\n",
      "Epoch 313/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8232 - val_loss: 0.5557 - val_accuracy: 0.8126\n",
      "Epoch 314/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8274 - val_loss: 0.5727 - val_accuracy: 0.8104\n",
      "Epoch 315/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8189 - val_loss: 0.5613 - val_accuracy: 0.8172\n",
      "Epoch 316/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8279 - val_loss: 0.5688 - val_accuracy: 0.8194\n",
      "Epoch 317/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8299 - val_loss: 0.5756 - val_accuracy: 0.8126\n",
      "Epoch 318/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8254 - val_loss: 0.5757 - val_accuracy: 0.8126\n",
      "Epoch 319/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8244 - val_loss: 0.5838 - val_accuracy: 0.8014\n",
      "Epoch 320/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8249 - val_loss: 0.5802 - val_accuracy: 0.8081\n",
      "Epoch 321/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8247 - val_loss: 0.5723 - val_accuracy: 0.8081\n",
      "Epoch 322/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8289 - val_loss: 0.5827 - val_accuracy: 0.8104\n",
      "Epoch 323/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8229 - val_loss: 0.5631 - val_accuracy: 0.8081\n",
      "Epoch 324/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8297 - val_loss: 0.5576 - val_accuracy: 0.8059\n",
      "Epoch 325/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8309 - val_loss: 0.5798 - val_accuracy: 0.8104\n",
      "Epoch 326/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8304 - val_loss: 0.5758 - val_accuracy: 0.8104\n",
      "Epoch 327/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8239 - val_loss: 0.5801 - val_accuracy: 0.8104\n",
      "Epoch 328/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8282 - val_loss: 0.5746 - val_accuracy: 0.8081\n",
      "Epoch 329/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8294 - val_loss: 0.5858 - val_accuracy: 0.8126\n",
      "Epoch 330/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8269 - val_loss: 0.5788 - val_accuracy: 0.8126\n",
      "Epoch 331/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8217 - val_loss: 0.5651 - val_accuracy: 0.8081\n",
      "Epoch 332/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8237 - val_loss: 0.5639 - val_accuracy: 0.8217\n",
      "Epoch 333/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8327 - val_loss: 0.5571 - val_accuracy: 0.8149\n",
      "Epoch 334/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8209 - val_loss: 0.5579 - val_accuracy: 0.8104\n",
      "Epoch 335/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8214 - val_loss: 0.5654 - val_accuracy: 0.8081\n",
      "Epoch 336/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8282 - val_loss: 0.5603 - val_accuracy: 0.8149\n",
      "Epoch 337/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8317 - val_loss: 0.5645 - val_accuracy: 0.8172\n",
      "Epoch 338/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8294 - val_loss: 0.5551 - val_accuracy: 0.8126\n",
      "Epoch 339/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8345 - val_loss: 0.5696 - val_accuracy: 0.8149\n",
      "Epoch 340/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8357 - val_loss: 0.5778 - val_accuracy: 0.8149\n",
      "Epoch 341/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8327 - val_loss: 0.5739 - val_accuracy: 0.8126\n",
      "Epoch 342/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8232 - val_loss: 0.5668 - val_accuracy: 0.8149\n",
      "Epoch 343/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8282 - val_loss: 0.5591 - val_accuracy: 0.8126\n",
      "Epoch 344/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8302 - val_loss: 0.5664 - val_accuracy: 0.8104\n",
      "Epoch 345/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.8249 - val_loss: 0.5721 - val_accuracy: 0.8104\n",
      "Epoch 346/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.8259 - val_loss: 0.5679 - val_accuracy: 0.8081\n",
      "Epoch 347/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.8304 - val_loss: 0.5697 - val_accuracy: 0.8149\n",
      "Epoch 348/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8259 - val_loss: 0.5551 - val_accuracy: 0.8149\n",
      "Epoch 349/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.8297 - val_loss: 0.5754 - val_accuracy: 0.8104\n",
      "Epoch 350/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8322 - val_loss: 0.5705 - val_accuracy: 0.8126\n",
      "Epoch 351/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8272 - val_loss: 0.5704 - val_accuracy: 0.8081\n",
      "Epoch 352/600\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.4150 - accuracy: 0.8242 - val_loss: 0.5793 - val_accuracy: 0.8194\n",
      "Epoch 353/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8259 - val_loss: 0.5782 - val_accuracy: 0.8104\n",
      "Epoch 354/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8259 - val_loss: 0.5829 - val_accuracy: 0.8059\n",
      "Epoch 355/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8267 - val_loss: 0.5886 - val_accuracy: 0.8059\n",
      "Epoch 356/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8212 - val_loss: 0.5694 - val_accuracy: 0.8126\n",
      "Epoch 357/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8365 - val_loss: 0.5819 - val_accuracy: 0.8104\n",
      "Epoch 358/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8259 - val_loss: 0.5735 - val_accuracy: 0.8081\n",
      "Epoch 359/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8259 - val_loss: 0.5657 - val_accuracy: 0.8104\n",
      "Epoch 360/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8272 - val_loss: 0.5783 - val_accuracy: 0.8149\n",
      "Epoch 361/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.8269 - val_loss: 0.5784 - val_accuracy: 0.8104\n",
      "Epoch 362/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8392 - val_loss: 0.5804 - val_accuracy: 0.8126\n",
      "Epoch 363/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8292 - val_loss: 0.5754 - val_accuracy: 0.8126\n",
      "Epoch 364/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8262 - val_loss: 0.5861 - val_accuracy: 0.8059\n",
      "Epoch 365/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8284 - val_loss: 0.5798 - val_accuracy: 0.8172\n",
      "Epoch 366/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8312 - val_loss: 0.5824 - val_accuracy: 0.8126\n",
      "Epoch 367/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8262 - val_loss: 0.5765 - val_accuracy: 0.8126\n",
      "Epoch 368/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8317 - val_loss: 0.5675 - val_accuracy: 0.8126\n",
      "Epoch 369/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8297 - val_loss: 0.5662 - val_accuracy: 0.8172\n",
      "Epoch 370/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8214 - val_loss: 0.5726 - val_accuracy: 0.8239\n",
      "Epoch 371/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8287 - val_loss: 0.5820 - val_accuracy: 0.8217\n",
      "Epoch 372/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8367 - val_loss: 0.5828 - val_accuracy: 0.8059\n",
      "Epoch 373/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8254 - val_loss: 0.5762 - val_accuracy: 0.8172\n",
      "Epoch 374/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8272 - val_loss: 0.5860 - val_accuracy: 0.8194\n",
      "Epoch 375/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8327 - val_loss: 0.5956 - val_accuracy: 0.8239\n",
      "Epoch 376/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8289 - val_loss: 0.5949 - val_accuracy: 0.8194\n",
      "Epoch 377/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8322 - val_loss: 0.5965 - val_accuracy: 0.8126\n",
      "Epoch 378/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8325 - val_loss: 0.5770 - val_accuracy: 0.8104\n",
      "Epoch 379/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8302 - val_loss: 0.5745 - val_accuracy: 0.8149\n",
      "Epoch 380/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8325 - val_loss: 0.5774 - val_accuracy: 0.8149\n",
      "Epoch 381/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8340 - val_loss: 0.5898 - val_accuracy: 0.8104\n",
      "Epoch 382/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8277 - val_loss: 0.5795 - val_accuracy: 0.8126\n",
      "Epoch 383/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8307 - val_loss: 0.5744 - val_accuracy: 0.8081\n",
      "Epoch 384/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8337 - val_loss: 0.5684 - val_accuracy: 0.8104\n",
      "Epoch 385/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8267 - val_loss: 0.5762 - val_accuracy: 0.8194\n",
      "Epoch 386/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8322 - val_loss: 0.5747 - val_accuracy: 0.8126\n",
      "Epoch 387/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8330 - val_loss: 0.5819 - val_accuracy: 0.8149\n",
      "Epoch 388/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8360 - val_loss: 0.5910 - val_accuracy: 0.8104\n",
      "Epoch 389/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8352 - val_loss: 0.5851 - val_accuracy: 0.8126\n",
      "Epoch 390/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8367 - val_loss: 0.5870 - val_accuracy: 0.8036\n",
      "Epoch 391/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8292 - val_loss: 0.5945 - val_accuracy: 0.8036\n",
      "Epoch 392/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8365 - val_loss: 0.5870 - val_accuracy: 0.8126\n",
      "Epoch 393/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8282 - val_loss: 0.6010 - val_accuracy: 0.8014\n",
      "Epoch 394/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8267 - val_loss: 0.5854 - val_accuracy: 0.8126\n",
      "Epoch 395/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8302 - val_loss: 0.5795 - val_accuracy: 0.8149\n",
      "Epoch 396/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8317 - val_loss: 0.5792 - val_accuracy: 0.8149\n",
      "Epoch 397/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8317 - val_loss: 0.5666 - val_accuracy: 0.8126\n",
      "Epoch 398/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8322 - val_loss: 0.5715 - val_accuracy: 0.8126\n",
      "Epoch 399/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8345 - val_loss: 0.5831 - val_accuracy: 0.8104\n",
      "Epoch 400/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8292 - val_loss: 0.5777 - val_accuracy: 0.8172\n",
      "Epoch 401/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8274 - val_loss: 0.5695 - val_accuracy: 0.8194\n",
      "Epoch 402/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8337 - val_loss: 0.5774 - val_accuracy: 0.8126\n",
      "Epoch 403/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8272 - val_loss: 0.5851 - val_accuracy: 0.8149\n",
      "Epoch 404/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8284 - val_loss: 0.5737 - val_accuracy: 0.8217\n",
      "Epoch 405/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8332 - val_loss: 0.5743 - val_accuracy: 0.8149\n",
      "Epoch 406/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8309 - val_loss: 0.5770 - val_accuracy: 0.8172\n",
      "Epoch 407/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8309 - val_loss: 0.5818 - val_accuracy: 0.8172\n",
      "Epoch 408/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8289 - val_loss: 0.5815 - val_accuracy: 0.8149\n",
      "Epoch 409/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8325 - val_loss: 0.5789 - val_accuracy: 0.8172\n",
      "Epoch 410/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8325 - val_loss: 0.5858 - val_accuracy: 0.8126\n",
      "Epoch 411/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8337 - val_loss: 0.5971 - val_accuracy: 0.8081\n",
      "Epoch 412/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8367 - val_loss: 0.5794 - val_accuracy: 0.8172\n",
      "Epoch 413/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8322 - val_loss: 0.5790 - val_accuracy: 0.8149\n",
      "Epoch 414/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8350 - val_loss: 0.5891 - val_accuracy: 0.8081\n",
      "Epoch 415/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8327 - val_loss: 0.5774 - val_accuracy: 0.8104\n",
      "Epoch 416/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8352 - val_loss: 0.5744 - val_accuracy: 0.8126\n",
      "Epoch 417/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8302 - val_loss: 0.5807 - val_accuracy: 0.8194\n",
      "Epoch 418/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8274 - val_loss: 0.5797 - val_accuracy: 0.8149\n",
      "Epoch 419/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8352 - val_loss: 0.5824 - val_accuracy: 0.8172\n",
      "Epoch 420/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8342 - val_loss: 0.5744 - val_accuracy: 0.8194\n",
      "Epoch 421/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8360 - val_loss: 0.5815 - val_accuracy: 0.8172\n",
      "Epoch 422/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8335 - val_loss: 0.5902 - val_accuracy: 0.8262\n",
      "Epoch 423/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8277 - val_loss: 0.5811 - val_accuracy: 0.8149\n",
      "Epoch 424/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8362 - val_loss: 0.5734 - val_accuracy: 0.8172\n",
      "Epoch 425/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8350 - val_loss: 0.5701 - val_accuracy: 0.8149\n",
      "Epoch 426/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8317 - val_loss: 0.5786 - val_accuracy: 0.8239\n",
      "Epoch 427/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8382 - val_loss: 0.5816 - val_accuracy: 0.8194\n",
      "Epoch 428/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8390 - val_loss: 0.5767 - val_accuracy: 0.8126\n",
      "Epoch 429/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8297 - val_loss: 0.5827 - val_accuracy: 0.8036\n",
      "Epoch 430/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.8352 - val_loss: 0.5923 - val_accuracy: 0.8126\n",
      "Epoch 431/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8355 - val_loss: 0.5768 - val_accuracy: 0.8149\n",
      "Epoch 432/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8320 - val_loss: 0.5703 - val_accuracy: 0.8217\n",
      "Epoch 433/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8415 - val_loss: 0.5836 - val_accuracy: 0.8172\n",
      "Epoch 434/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8375 - val_loss: 0.5902 - val_accuracy: 0.8149\n",
      "Epoch 435/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8312 - val_loss: 0.5777 - val_accuracy: 0.8217\n",
      "Epoch 436/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8322 - val_loss: 0.5631 - val_accuracy: 0.8126\n",
      "Epoch 437/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4078 - accuracy: 0.8340 - val_loss: 0.5812 - val_accuracy: 0.8172\n",
      "Epoch 438/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8412 - val_loss: 0.5964 - val_accuracy: 0.8194\n",
      "Epoch 439/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8365 - val_loss: 0.5840 - val_accuracy: 0.8172\n",
      "Epoch 440/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8375 - val_loss: 0.5832 - val_accuracy: 0.8149\n",
      "Epoch 441/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8357 - val_loss: 0.5881 - val_accuracy: 0.8172\n",
      "Epoch 442/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8259 - val_loss: 0.5899 - val_accuracy: 0.8149\n",
      "Epoch 443/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8335 - val_loss: 0.5883 - val_accuracy: 0.8172\n",
      "Epoch 444/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8347 - val_loss: 0.5841 - val_accuracy: 0.8104\n",
      "Epoch 445/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8347 - val_loss: 0.5788 - val_accuracy: 0.8194\n",
      "Epoch 446/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8372 - val_loss: 0.5838 - val_accuracy: 0.8126\n",
      "Epoch 447/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8407 - val_loss: 0.5907 - val_accuracy: 0.8126\n",
      "Epoch 448/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8350 - val_loss: 0.5856 - val_accuracy: 0.8104\n",
      "Epoch 449/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8365 - val_loss: 0.5897 - val_accuracy: 0.8172\n",
      "Epoch 450/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8392 - val_loss: 0.5991 - val_accuracy: 0.8104\n",
      "Epoch 451/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8355 - val_loss: 0.5897 - val_accuracy: 0.8172\n",
      "Epoch 452/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8375 - val_loss: 0.5960 - val_accuracy: 0.8194\n",
      "Epoch 453/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8337 - val_loss: 0.6069 - val_accuracy: 0.8149\n",
      "Epoch 454/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8309 - val_loss: 0.5944 - val_accuracy: 0.8149\n",
      "Epoch 455/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8330 - val_loss: 0.5910 - val_accuracy: 0.8194\n",
      "Epoch 456/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8345 - val_loss: 0.6050 - val_accuracy: 0.8149\n",
      "Epoch 457/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8277 - val_loss: 0.5997 - val_accuracy: 0.8126\n",
      "Epoch 458/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8382 - val_loss: 0.5987 - val_accuracy: 0.8126\n",
      "Epoch 459/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8322 - val_loss: 0.5822 - val_accuracy: 0.8172\n",
      "Epoch 460/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8370 - val_loss: 0.5862 - val_accuracy: 0.8149\n",
      "Epoch 461/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8262 - val_loss: 0.5786 - val_accuracy: 0.8217\n",
      "Epoch 462/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8340 - val_loss: 0.5799 - val_accuracy: 0.8172\n",
      "Epoch 463/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8365 - val_loss: 0.5812 - val_accuracy: 0.8172\n",
      "Epoch 464/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8342 - val_loss: 0.5888 - val_accuracy: 0.8104\n",
      "Epoch 465/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8332 - val_loss: 0.5826 - val_accuracy: 0.8126\n",
      "Epoch 466/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8382 - val_loss: 0.5939 - val_accuracy: 0.8126\n",
      "Epoch 467/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8332 - val_loss: 0.5923 - val_accuracy: 0.8194\n",
      "Epoch 468/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8299 - val_loss: 0.5816 - val_accuracy: 0.8284\n",
      "Epoch 469/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8385 - val_loss: 0.5835 - val_accuracy: 0.8217\n",
      "Epoch 470/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8345 - val_loss: 0.5822 - val_accuracy: 0.8172\n",
      "Epoch 471/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8380 - val_loss: 0.5925 - val_accuracy: 0.8194\n",
      "Epoch 472/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8370 - val_loss: 0.5896 - val_accuracy: 0.8126\n",
      "Epoch 473/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8377 - val_loss: 0.5901 - val_accuracy: 0.8149\n",
      "Epoch 474/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8302 - val_loss: 0.5875 - val_accuracy: 0.8194\n",
      "Epoch 475/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8390 - val_loss: 0.5959 - val_accuracy: 0.8149\n",
      "Epoch 476/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8317 - val_loss: 0.5971 - val_accuracy: 0.8036\n",
      "Epoch 477/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8400 - val_loss: 0.6095 - val_accuracy: 0.8081\n",
      "Epoch 478/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8320 - val_loss: 0.5975 - val_accuracy: 0.8239\n",
      "Epoch 479/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8395 - val_loss: 0.5968 - val_accuracy: 0.8059\n",
      "Epoch 480/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8345 - val_loss: 0.6011 - val_accuracy: 0.8172\n",
      "Epoch 481/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8355 - val_loss: 0.6199 - val_accuracy: 0.7991\n",
      "Epoch 482/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8350 - val_loss: 0.5904 - val_accuracy: 0.8172\n",
      "Epoch 483/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8360 - val_loss: 0.5975 - val_accuracy: 0.8217\n",
      "Epoch 484/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8347 - val_loss: 0.6094 - val_accuracy: 0.8104\n",
      "Epoch 485/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8347 - val_loss: 0.6016 - val_accuracy: 0.8104\n",
      "Epoch 486/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8410 - val_loss: 0.6179 - val_accuracy: 0.8149\n",
      "Epoch 487/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8377 - val_loss: 0.6240 - val_accuracy: 0.8104\n",
      "Epoch 488/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8352 - val_loss: 0.6202 - val_accuracy: 0.8036\n",
      "Epoch 489/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8415 - val_loss: 0.6044 - val_accuracy: 0.8126\n",
      "Epoch 490/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8357 - val_loss: 0.5978 - val_accuracy: 0.8014\n",
      "Epoch 491/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8367 - val_loss: 0.6160 - val_accuracy: 0.8081\n",
      "Epoch 492/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8350 - val_loss: 0.6111 - val_accuracy: 0.8081\n",
      "Epoch 493/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8420 - val_loss: 0.5993 - val_accuracy: 0.8126\n",
      "Epoch 494/600\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8412 - val_loss: 0.6041 - val_accuracy: 0.8059\n",
      "Epoch 495/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8365 - val_loss: 0.5942 - val_accuracy: 0.8104\n",
      "Epoch 496/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8428 - val_loss: 0.6179 - val_accuracy: 0.8104\n",
      "Epoch 497/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8428 - val_loss: 0.6056 - val_accuracy: 0.8081\n",
      "Epoch 498/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8375 - val_loss: 0.6051 - val_accuracy: 0.8126\n",
      "Epoch 499/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8365 - val_loss: 0.5828 - val_accuracy: 0.8104\n",
      "Epoch 500/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8362 - val_loss: 0.5809 - val_accuracy: 0.8104\n",
      "Epoch 501/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8337 - val_loss: 0.5988 - val_accuracy: 0.8059\n",
      "Epoch 502/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8415 - val_loss: 0.5951 - val_accuracy: 0.8126\n",
      "Epoch 503/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8380 - val_loss: 0.5913 - val_accuracy: 0.8172\n",
      "Epoch 504/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8360 - val_loss: 0.6115 - val_accuracy: 0.8081\n",
      "Epoch 505/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8327 - val_loss: 0.5978 - val_accuracy: 0.8217\n",
      "Epoch 506/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8448 - val_loss: 0.6013 - val_accuracy: 0.8149\n",
      "Epoch 507/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8397 - val_loss: 0.6052 - val_accuracy: 0.8172\n",
      "Epoch 508/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8367 - val_loss: 0.6014 - val_accuracy: 0.8081\n",
      "Epoch 509/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8377 - val_loss: 0.5900 - val_accuracy: 0.8239\n",
      "Epoch 510/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8390 - val_loss: 0.6092 - val_accuracy: 0.8194\n",
      "Epoch 511/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8425 - val_loss: 0.5998 - val_accuracy: 0.8081\n",
      "Epoch 512/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8392 - val_loss: 0.6043 - val_accuracy: 0.8149\n",
      "Epoch 513/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8415 - val_loss: 0.6010 - val_accuracy: 0.8172\n",
      "Epoch 514/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8365 - val_loss: 0.5925 - val_accuracy: 0.8126\n",
      "Epoch 515/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8370 - val_loss: 0.5857 - val_accuracy: 0.8194\n",
      "Epoch 516/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.8392 - val_loss: 0.5841 - val_accuracy: 0.8194\n",
      "Epoch 517/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8355 - val_loss: 0.5849 - val_accuracy: 0.8149\n",
      "Epoch 518/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8355 - val_loss: 0.5772 - val_accuracy: 0.8194\n",
      "Epoch 519/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8380 - val_loss: 0.5882 - val_accuracy: 0.8194\n",
      "Epoch 520/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8430 - val_loss: 0.5964 - val_accuracy: 0.8217\n",
      "Epoch 521/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8380 - val_loss: 0.5786 - val_accuracy: 0.8172\n",
      "Epoch 522/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8420 - val_loss: 0.5959 - val_accuracy: 0.8284\n",
      "Epoch 523/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8375 - val_loss: 0.6000 - val_accuracy: 0.8081\n",
      "Epoch 524/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8375 - val_loss: 0.5901 - val_accuracy: 0.8172\n",
      "Epoch 525/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8392 - val_loss: 0.5972 - val_accuracy: 0.8126\n",
      "Epoch 526/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8367 - val_loss: 0.6076 - val_accuracy: 0.8059\n",
      "Epoch 527/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8410 - val_loss: 0.6036 - val_accuracy: 0.8059\n",
      "Epoch 528/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8402 - val_loss: 0.6106 - val_accuracy: 0.8059\n",
      "Epoch 529/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8385 - val_loss: 0.5930 - val_accuracy: 0.8126\n",
      "Epoch 530/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8412 - val_loss: 0.6068 - val_accuracy: 0.8014\n",
      "Epoch 531/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8385 - val_loss: 0.5963 - val_accuracy: 0.8059\n",
      "Epoch 532/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8284 - val_loss: 0.5884 - val_accuracy: 0.8104\n",
      "Epoch 533/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8450 - val_loss: 0.5914 - val_accuracy: 0.8126\n",
      "Epoch 534/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8448 - val_loss: 0.5856 - val_accuracy: 0.8284\n",
      "Epoch 535/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8420 - val_loss: 0.5818 - val_accuracy: 0.8194\n",
      "Epoch 536/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8465 - val_loss: 0.5957 - val_accuracy: 0.8262\n",
      "Epoch 537/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8335 - val_loss: 0.5885 - val_accuracy: 0.8149\n",
      "Epoch 538/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8392 - val_loss: 0.5946 - val_accuracy: 0.8194\n",
      "Epoch 539/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8362 - val_loss: 0.5971 - val_accuracy: 0.8194\n",
      "Epoch 540/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8425 - val_loss: 0.6012 - val_accuracy: 0.8172\n",
      "Epoch 541/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8367 - val_loss: 0.6025 - val_accuracy: 0.8126\n",
      "Epoch 542/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8325 - val_loss: 0.5815 - val_accuracy: 0.8217\n",
      "Epoch 543/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8433 - val_loss: 0.5955 - val_accuracy: 0.8172\n",
      "Epoch 544/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8463 - val_loss: 0.5992 - val_accuracy: 0.8081\n",
      "Epoch 545/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8385 - val_loss: 0.6072 - val_accuracy: 0.8172\n",
      "Epoch 546/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8370 - val_loss: 0.6171 - val_accuracy: 0.8126\n",
      "Epoch 547/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8468 - val_loss: 0.6172 - val_accuracy: 0.8194\n",
      "Epoch 548/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8375 - val_loss: 0.6068 - val_accuracy: 0.8172\n",
      "Epoch 549/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8410 - val_loss: 0.5935 - val_accuracy: 0.8172\n",
      "Epoch 550/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8420 - val_loss: 0.5937 - val_accuracy: 0.8126\n",
      "Epoch 551/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8362 - val_loss: 0.5898 - val_accuracy: 0.8149\n",
      "Epoch 552/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8387 - val_loss: 0.5845 - val_accuracy: 0.8239\n",
      "Epoch 553/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8382 - val_loss: 0.5859 - val_accuracy: 0.8149\n",
      "Epoch 554/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8410 - val_loss: 0.5968 - val_accuracy: 0.8126\n",
      "Epoch 555/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8375 - val_loss: 0.5997 - val_accuracy: 0.8149\n",
      "Epoch 556/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8355 - val_loss: 0.5969 - val_accuracy: 0.8172\n",
      "Epoch 557/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8415 - val_loss: 0.5988 - val_accuracy: 0.8194\n",
      "Epoch 558/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8397 - val_loss: 0.5980 - val_accuracy: 0.8149\n",
      "Epoch 559/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8377 - val_loss: 0.6020 - val_accuracy: 0.8149\n",
      "Epoch 560/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8412 - val_loss: 0.6100 - val_accuracy: 0.8126\n",
      "Epoch 561/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8402 - val_loss: 0.6168 - val_accuracy: 0.8104\n",
      "Epoch 562/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8355 - val_loss: 0.6178 - val_accuracy: 0.8126\n",
      "Epoch 563/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8435 - val_loss: 0.6214 - val_accuracy: 0.8126\n",
      "Epoch 564/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8307 - val_loss: 0.6150 - val_accuracy: 0.8059\n",
      "Epoch 565/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8377 - val_loss: 0.6035 - val_accuracy: 0.8126\n",
      "Epoch 566/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8345 - val_loss: 0.6024 - val_accuracy: 0.8081\n",
      "Epoch 567/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8438 - val_loss: 0.6020 - val_accuracy: 0.8194\n",
      "Epoch 568/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8417 - val_loss: 0.6067 - val_accuracy: 0.8217\n",
      "Epoch 569/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8357 - val_loss: 0.6019 - val_accuracy: 0.8194\n",
      "Epoch 570/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8440 - val_loss: 0.6006 - val_accuracy: 0.8149\n",
      "Epoch 571/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8430 - val_loss: 0.6158 - val_accuracy: 0.8126\n",
      "Epoch 572/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8405 - val_loss: 0.6038 - val_accuracy: 0.8014\n",
      "Epoch 573/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8382 - val_loss: 0.6001 - val_accuracy: 0.8194\n",
      "Epoch 574/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8435 - val_loss: 0.6034 - val_accuracy: 0.8059\n",
      "Epoch 575/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8397 - val_loss: 0.5966 - val_accuracy: 0.8149\n",
      "Epoch 576/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8365 - val_loss: 0.6107 - val_accuracy: 0.8149\n",
      "Epoch 577/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8345 - val_loss: 0.6212 - val_accuracy: 0.8194\n",
      "Epoch 578/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8392 - val_loss: 0.6033 - val_accuracy: 0.8172\n",
      "Epoch 579/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8385 - val_loss: 0.6008 - val_accuracy: 0.8149\n",
      "Epoch 580/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8385 - val_loss: 0.5976 - val_accuracy: 0.8126\n",
      "Epoch 581/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8357 - val_loss: 0.5975 - val_accuracy: 0.8217\n",
      "Epoch 582/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8468 - val_loss: 0.5893 - val_accuracy: 0.8149\n",
      "Epoch 583/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8352 - val_loss: 0.6069 - val_accuracy: 0.8126\n",
      "Epoch 584/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8367 - val_loss: 0.6016 - val_accuracy: 0.8149\n",
      "Epoch 585/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.8387 - val_loss: 0.6002 - val_accuracy: 0.8081\n",
      "Epoch 586/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8387 - val_loss: 0.5980 - val_accuracy: 0.8149\n",
      "Epoch 587/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8410 - val_loss: 0.6084 - val_accuracy: 0.8149\n",
      "Epoch 588/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8342 - val_loss: 0.6163 - val_accuracy: 0.8149\n",
      "Epoch 589/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8365 - val_loss: 0.6169 - val_accuracy: 0.8126\n",
      "Epoch 590/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8428 - val_loss: 0.6209 - val_accuracy: 0.8081\n",
      "Epoch 591/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8370 - val_loss: 0.6115 - val_accuracy: 0.7991\n",
      "Epoch 592/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8435 - val_loss: 0.6207 - val_accuracy: 0.8149\n",
      "Epoch 593/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8450 - val_loss: 0.6160 - val_accuracy: 0.8036\n",
      "Epoch 594/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8428 - val_loss: 0.6284 - val_accuracy: 0.8126\n",
      "Epoch 595/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8372 - val_loss: 0.6196 - val_accuracy: 0.8081\n",
      "Epoch 596/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8385 - val_loss: 0.6104 - val_accuracy: 0.8217\n",
      "Epoch 597/600\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8468 - val_loss: 0.6172 - val_accuracy: 0.8194\n",
      "Epoch 598/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8397 - val_loss: 0.6145 - val_accuracy: 0.8217\n",
      "Epoch 599/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8430 - val_loss: 0.6223 - val_accuracy: 0.8149\n",
      "Epoch 600/600\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8385 - val_loss: 0.6140 - val_accuracy: 0.8104\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 600, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('drop_out_predict_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "later_model = load_model('drop_out_predict_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()\n",
    "plt.savefig('evaluate.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a random student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital status                                       1.000000\n",
       "Application mode                                    17.000000\n",
       "Application order                                    1.000000\n",
       "Course                                            9853.000000\n",
       "Daytime/evening attendance                           1.000000\n",
       "Previous qualification                               1.000000\n",
       "Previous qualification (grade)                     125.000000\n",
       "Nacionality                                          1.000000\n",
       "Mother's qualification                              19.000000\n",
       "Father's qualification                              19.000000\n",
       "Mother's occupation                                  4.000000\n",
       "Father's occupation                                  7.000000\n",
       "Admission grade                                    128.500000\n",
       "Displaced                                            1.000000\n",
       "Educational special needs                            0.000000\n",
       "Debtor                                               0.000000\n",
       "Tuition fees up to date                              1.000000\n",
       "Gender                                               0.000000\n",
       "Scholarship holder                                   0.000000\n",
       "Age at enrollment                                   18.000000\n",
       "International                                        0.000000\n",
       "Curricular units 1st sem (credited)                  0.000000\n",
       "Curricular units 1st sem (enrolled)                  7.000000\n",
       "Curricular units 1st sem (evaluations)               9.000000\n",
       "Curricular units 1st sem (approved)                  6.000000\n",
       "Curricular units 1st sem (grade)                    11.500000\n",
       "Curricular units 1st sem (without evaluations)       0.000000\n",
       "Curricular units 2nd sem (credited)                  0.000000\n",
       "Curricular units 2nd sem (enrolled)                  7.000000\n",
       "Curricular units 2nd sem (evaluations)               8.000000\n",
       "Curricular units 2nd sem (approved)                  7.000000\n",
       "Curricular units 2nd sem (grade)                    12.714286\n",
       "Curricular units 2nd sem (without evaluations)       0.000000\n",
       "Unemployment rate                                   13.900000\n",
       "Inflation rate                                      -0.300000\n",
       "GDP                                                  0.790000\n",
       "Name: 1195, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(87)\n",
    "random_ind = random.randint(0, len(dataset))\n",
    "\n",
    "new_student = dataset.drop('Target',axis = 1).iloc[random_ind]\n",
    "new_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(new_student.values.reshape(1,36)) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Enrolled'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[random_ind]['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.7697516930022573\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85       140\n",
      "           1       0.50      0.30      0.37        64\n",
      "           2       0.84      0.87      0.86       239\n",
      "\n",
      "   micro avg       0.83      0.77      0.80       443\n",
      "   macro avg       0.75      0.66      0.69       443\n",
      "weighted avg       0.81      0.77      0.79       443\n",
      " samples avg       0.77      0.77      0.77       443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score:',accuracy_score(y_test, predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
