{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Essential Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "IBXRF3JsTKP1",
        "outputId": "82629e61-5b6c-4643-ff57-701c5cad535b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Previous qualification (grade)</th>\n",
              "      <th>Nacionality</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 2nd sem (credited)</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>171</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>9254</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>160.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>9070</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>9773</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-3.12</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>8014</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>9991</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>133.1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>5</td>\n",
              "      <td>16.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9500</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>142.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>14.345000</td>\n",
              "      <td>0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-4.06</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>9254</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>119.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-4.06</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>137.0</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>14.142857</td>\n",
              "      <td>0</td>\n",
              "      <td>16.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>138.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>3.51</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Marital status  Application mode  Application order  Course  \\\n",
              "0               1                17                  5     171   \n",
              "1               1                15                  1    9254   \n",
              "2               1                 1                  5    9070   \n",
              "3               1                17                  2    9773   \n",
              "4               2                39                  1    8014   \n",
              "5               2                39                  1    9991   \n",
              "6               1                 1                  1    9500   \n",
              "7               1                18                  4    9254   \n",
              "8               1                 1                  3    9238   \n",
              "9               1                 1                  1    9238   \n",
              "\n",
              "   Daytime/evening attendance  Previous qualification  \\\n",
              "0                           1                       1   \n",
              "1                           1                       1   \n",
              "2                           1                       1   \n",
              "3                           1                       1   \n",
              "4                           0                       1   \n",
              "5                           0                      19   \n",
              "6                           1                       1   \n",
              "7                           1                       1   \n",
              "8                           1                       1   \n",
              "9                           1                       1   \n",
              "\n",
              "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
              "0                           122.0            1                      19   \n",
              "1                           160.0            1                       1   \n",
              "2                           122.0            1                      37   \n",
              "3                           122.0            1                      38   \n",
              "4                           100.0            1                      37   \n",
              "5                           133.1            1                      37   \n",
              "6                           142.0            1                      19   \n",
              "7                           119.0            1                      37   \n",
              "8                           137.0           62                       1   \n",
              "9                           138.0            1                       1   \n",
              "\n",
              "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
              "0                      12  ...                                    0   \n",
              "1                       3  ...                                    0   \n",
              "2                      37  ...                                    0   \n",
              "3                      37  ...                                    0   \n",
              "4                      38  ...                                    0   \n",
              "5                      37  ...                                    0   \n",
              "6                      38  ...                                    0   \n",
              "7                      37  ...                                    0   \n",
              "8                       1  ...                                    0   \n",
              "9                      19  ...                                    0   \n",
              "\n",
              "   Curricular units 2nd sem (enrolled)  \\\n",
              "0                                    0   \n",
              "1                                    6   \n",
              "2                                    6   \n",
              "3                                    6   \n",
              "4                                    6   \n",
              "5                                    5   \n",
              "6                                    8   \n",
              "7                                    5   \n",
              "8                                    6   \n",
              "9                                    6   \n",
              "\n",
              "   Curricular units 2nd sem (evaluations)  \\\n",
              "0                                       0   \n",
              "1                                       6   \n",
              "2                                       0   \n",
              "3                                      10   \n",
              "4                                       6   \n",
              "5                                      17   \n",
              "6                                       8   \n",
              "7                                       5   \n",
              "8                                       7   \n",
              "9                                      14   \n",
              "\n",
              "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "0                                    0                          0.000000   \n",
              "1                                    6                         13.666667   \n",
              "2                                    0                          0.000000   \n",
              "3                                    5                         12.400000   \n",
              "4                                    6                         13.000000   \n",
              "5                                    5                         11.500000   \n",
              "6                                    8                         14.345000   \n",
              "7                                    0                          0.000000   \n",
              "8                                    6                         14.142857   \n",
              "9                                    2                         13.500000   \n",
              "\n",
              "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "0                                               0               10.8   \n",
              "1                                               0               13.9   \n",
              "2                                               0               10.8   \n",
              "3                                               0                9.4   \n",
              "4                                               0               13.9   \n",
              "5                                               5               16.2   \n",
              "6                                               0               15.5   \n",
              "7                                               0               15.5   \n",
              "8                                               0               16.2   \n",
              "9                                               0                8.9   \n",
              "\n",
              "   Inflation rate   GDP    Target  \n",
              "0             1.4  1.74   Dropout  \n",
              "1            -0.3  0.79  Graduate  \n",
              "2             1.4  1.74   Dropout  \n",
              "3            -0.8 -3.12  Graduate  \n",
              "4            -0.3  0.79  Graduate  \n",
              "5             0.3 -0.92  Graduate  \n",
              "6             2.8 -4.06  Graduate  \n",
              "7             2.8 -4.06   Dropout  \n",
              "8             0.3 -0.92  Graduate  \n",
              "9             1.4  3.51   Dropout  \n",
              "\n",
              "[10 rows x 37 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#dataset import\n",
        "dataset = pd.read_csv('data.csv') #You need to change #directory accordingly\n",
        "dataset.head(10) #Return 10 rows of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enhance Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-buQfLLrTUuc",
        "outputId": "a2a4d63b-9384-41c1-d876-7e01888bd5be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Graduate    2209\n",
              "Dropout     1421\n",
              "Enrolled     794\n",
              "Name: Target, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['Target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrolQem-TV34",
        "outputId": "9fb6d231-42e5-4818-c527-ebf4e38330e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4424, 36)\n",
            "(4424, 1)\n"
          ]
        }
      ],
      "source": [
        "#Changing pandas dataframe to numpy array\n",
        "X = dataset.iloc[:,:36].values\n",
        "y = dataset.iloc[:,36:37].values\n",
        "y[10:40]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KlGwVDaATWqX"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(k_neighbors = 15)\n",
        "X, y = smote.fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LjzwqovUI80",
        "outputId": "66659f20-03c4-498f-a148-885b4471d82c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['Dropout', 'Enrolled', 'Graduate'], dtype=object),\n",
              " array([2209, 2209, 2209], dtype=int64))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique = np.unique(y, return_counts = True)\n",
        "unique\n",
        "# (array(['Dropout', 'Enrolled', 'Graduate'], dtype=object),\n",
        "# array([2209, 2209, 2209], dtype=int64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One - hot Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYJucrgfTayV",
        "outputId": "26f8fc07-1278-4070-d620-9823cfa479b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "dummy_y[10:40]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DXMxCBmrTb7t"
      },
      "outputs": [],
      "source": [
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zNTX22OkTnnA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXy42Nh0TohO",
        "outputId": "e47e5439-e589-47a0-e4b9-d9c92d19651a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5964, 36)\n",
            "(5964, 3)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "y4Uk8Yh7TpU3"
      },
      "outputs": [],
      "source": [
        "#Dependencies\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "# Neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units = 3, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cgYoymXmTuiE"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-c-Ns3ZTwAU",
        "outputId": "de55cae0-f262-4ecd-d7e6-c30d78f605b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.7402 - accuracy: 0.6715 - val_loss: 0.6519 - val_accuracy: 0.7345\n",
            "Epoch 2/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.6206 - accuracy: 0.7466 - val_loss: 0.5899 - val_accuracy: 0.7511\n",
            "Epoch 3/400\n",
            "120/120 [==============================] - 3s 25ms/step - loss: 0.5612 - accuracy: 0.7671 - val_loss: 0.5428 - val_accuracy: 0.8054\n",
            "Epoch 4/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.5258 - accuracy: 0.7862 - val_loss: 0.5484 - val_accuracy: 0.7813\n",
            "Epoch 5/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.4983 - accuracy: 0.7995 - val_loss: 0.5187 - val_accuracy: 0.7934\n",
            "Epoch 6/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.4600 - accuracy: 0.8124 - val_loss: 0.5706 - val_accuracy: 0.7888\n",
            "Epoch 7/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.4346 - accuracy: 0.8273 - val_loss: 0.5214 - val_accuracy: 0.7934\n",
            "Epoch 8/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.4152 - accuracy: 0.8358 - val_loss: 0.5261 - val_accuracy: 0.8205\n",
            "Epoch 9/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.3842 - accuracy: 0.8483 - val_loss: 0.5592 - val_accuracy: 0.7964\n",
            "Epoch 10/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.3609 - accuracy: 0.8561 - val_loss: 0.5164 - val_accuracy: 0.8250\n",
            "Epoch 11/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.3397 - accuracy: 0.8711 - val_loss: 0.4769 - val_accuracy: 0.8311\n",
            "Epoch 12/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.3149 - accuracy: 0.8764 - val_loss: 0.5260 - val_accuracy: 0.8341\n",
            "Epoch 13/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.3027 - accuracy: 0.8820 - val_loss: 0.5081 - val_accuracy: 0.8250\n",
            "Epoch 14/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.2949 - accuracy: 0.8841 - val_loss: 0.5577 - val_accuracy: 0.8265\n",
            "Epoch 15/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.2704 - accuracy: 0.8957 - val_loss: 0.5946 - val_accuracy: 0.8250\n",
            "Epoch 16/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.2545 - accuracy: 0.9034 - val_loss: 0.6098 - val_accuracy: 0.8220\n",
            "Epoch 17/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.2406 - accuracy: 0.9044 - val_loss: 0.5995 - val_accuracy: 0.8311\n",
            "Epoch 18/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.2197 - accuracy: 0.9136 - val_loss: 0.6275 - val_accuracy: 0.8220\n",
            "Epoch 19/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.2342 - accuracy: 0.9103 - val_loss: 0.5107 - val_accuracy: 0.8567\n",
            "Epoch 20/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1981 - accuracy: 0.9237 - val_loss: 0.6642 - val_accuracy: 0.8386\n",
            "Epoch 21/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.2045 - accuracy: 0.9225 - val_loss: 0.5815 - val_accuracy: 0.8477\n",
            "Epoch 22/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1942 - accuracy: 0.9272 - val_loss: 0.5963 - val_accuracy: 0.8296\n",
            "Epoch 23/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1886 - accuracy: 0.9334 - val_loss: 0.5845 - val_accuracy: 0.8431\n",
            "Epoch 24/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1609 - accuracy: 0.9413 - val_loss: 0.6491 - val_accuracy: 0.8462\n",
            "Epoch 25/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.1655 - accuracy: 0.9381 - val_loss: 0.5915 - val_accuracy: 0.8431\n",
            "Epoch 26/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1663 - accuracy: 0.9385 - val_loss: 0.6569 - val_accuracy: 0.8265\n",
            "Epoch 27/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1516 - accuracy: 0.9462 - val_loss: 0.6576 - val_accuracy: 0.8522\n",
            "Epoch 28/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.1471 - accuracy: 0.9433 - val_loss: 0.7899 - val_accuracy: 0.8507\n",
            "Epoch 29/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.1464 - accuracy: 0.9450 - val_loss: 0.6013 - val_accuracy: 0.8552\n",
            "Epoch 30/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1357 - accuracy: 0.9467 - val_loss: 0.6233 - val_accuracy: 0.8416\n",
            "Epoch 31/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1290 - accuracy: 0.9519 - val_loss: 0.6013 - val_accuracy: 0.8582\n",
            "Epoch 32/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1155 - accuracy: 0.9567 - val_loss: 0.7190 - val_accuracy: 0.8507\n",
            "Epoch 33/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1156 - accuracy: 0.9552 - val_loss: 0.6514 - val_accuracy: 0.8477\n",
            "Epoch 34/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1164 - accuracy: 0.9552 - val_loss: 0.6686 - val_accuracy: 0.8537\n",
            "Epoch 35/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1217 - accuracy: 0.9549 - val_loss: 0.6470 - val_accuracy: 0.8401\n",
            "Epoch 36/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1145 - accuracy: 0.9586 - val_loss: 0.8535 - val_accuracy: 0.8326\n",
            "Epoch 37/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.1062 - accuracy: 0.9572 - val_loss: 0.7321 - val_accuracy: 0.8371\n",
            "Epoch 38/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1155 - accuracy: 0.9581 - val_loss: 0.7194 - val_accuracy: 0.8492\n",
            "Epoch 39/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.1136 - accuracy: 0.9579 - val_loss: 0.8013 - val_accuracy: 0.8627\n",
            "Epoch 40/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1020 - accuracy: 0.9604 - val_loss: 0.6711 - val_accuracy: 0.8462\n",
            "Epoch 41/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0958 - accuracy: 0.9658 - val_loss: 0.7673 - val_accuracy: 0.8582\n",
            "Epoch 42/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.1032 - accuracy: 0.9634 - val_loss: 0.7412 - val_accuracy: 0.8703\n",
            "Epoch 43/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0950 - accuracy: 0.9656 - val_loss: 0.7573 - val_accuracy: 0.8567\n",
            "Epoch 44/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0897 - accuracy: 0.9691 - val_loss: 0.7495 - val_accuracy: 0.8446\n",
            "Epoch 45/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0939 - accuracy: 0.9665 - val_loss: 0.6970 - val_accuracy: 0.8477\n",
            "Epoch 46/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0828 - accuracy: 0.9708 - val_loss: 0.7529 - val_accuracy: 0.8522\n",
            "Epoch 47/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0797 - accuracy: 0.9700 - val_loss: 0.7387 - val_accuracy: 0.8416\n",
            "Epoch 48/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0844 - accuracy: 0.9707 - val_loss: 0.7279 - val_accuracy: 0.8462\n",
            "Epoch 49/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0891 - accuracy: 0.9710 - val_loss: 0.7662 - val_accuracy: 0.8643\n",
            "Epoch 50/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0806 - accuracy: 0.9712 - val_loss: 0.8503 - val_accuracy: 0.8492\n",
            "Epoch 51/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0834 - accuracy: 0.9710 - val_loss: 0.6877 - val_accuracy: 0.8507\n",
            "Epoch 52/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0932 - accuracy: 0.9658 - val_loss: 0.7082 - val_accuracy: 0.8416\n",
            "Epoch 53/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0784 - accuracy: 0.9735 - val_loss: 0.8459 - val_accuracy: 0.8431\n",
            "Epoch 54/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0719 - accuracy: 0.9754 - val_loss: 0.6747 - val_accuracy: 0.8567\n",
            "Epoch 55/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0822 - accuracy: 0.9720 - val_loss: 0.7282 - val_accuracy: 0.8492\n",
            "Epoch 56/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0657 - accuracy: 0.9770 - val_loss: 0.7977 - val_accuracy: 0.8431\n",
            "Epoch 57/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0770 - accuracy: 0.9728 - val_loss: 0.7974 - val_accuracy: 0.8401\n",
            "Epoch 58/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0788 - accuracy: 0.9702 - val_loss: 0.8256 - val_accuracy: 0.8537\n",
            "Epoch 59/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0707 - accuracy: 0.9747 - val_loss: 0.8193 - val_accuracy: 0.8597\n",
            "Epoch 60/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0767 - accuracy: 0.9722 - val_loss: 0.7907 - val_accuracy: 0.8522\n",
            "Epoch 61/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0658 - accuracy: 0.9772 - val_loss: 0.9106 - val_accuracy: 0.8567\n",
            "Epoch 62/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0643 - accuracy: 0.9792 - val_loss: 0.7988 - val_accuracy: 0.8688\n",
            "Epoch 63/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0704 - accuracy: 0.9748 - val_loss: 0.9134 - val_accuracy: 0.8492\n",
            "Epoch 64/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0638 - accuracy: 0.9789 - val_loss: 0.9772 - val_accuracy: 0.8416\n",
            "Epoch 65/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0625 - accuracy: 0.9779 - val_loss: 0.8905 - val_accuracy: 0.8627\n",
            "Epoch 66/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0648 - accuracy: 0.9780 - val_loss: 0.9084 - val_accuracy: 0.8552\n",
            "Epoch 67/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0615 - accuracy: 0.9777 - val_loss: 1.0116 - val_accuracy: 0.8371\n",
            "Epoch 68/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0679 - accuracy: 0.9762 - val_loss: 0.9307 - val_accuracy: 0.8446\n",
            "Epoch 69/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0615 - accuracy: 0.9774 - val_loss: 0.8171 - val_accuracy: 0.8552\n",
            "Epoch 70/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0603 - accuracy: 0.9759 - val_loss: 0.9147 - val_accuracy: 0.8627\n",
            "Epoch 71/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0748 - accuracy: 0.9760 - val_loss: 0.7746 - val_accuracy: 0.8718\n",
            "Epoch 72/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0506 - accuracy: 0.9814 - val_loss: 0.8928 - val_accuracy: 0.8401\n",
            "Epoch 73/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0596 - accuracy: 0.9767 - val_loss: 0.9275 - val_accuracy: 0.8507\n",
            "Epoch 74/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0696 - accuracy: 0.9750 - val_loss: 1.1401 - val_accuracy: 0.8386\n",
            "Epoch 75/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0670 - accuracy: 0.9779 - val_loss: 0.8232 - val_accuracy: 0.8341\n",
            "Epoch 76/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0576 - accuracy: 0.9780 - val_loss: 0.8519 - val_accuracy: 0.8446\n",
            "Epoch 77/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0640 - accuracy: 0.9787 - val_loss: 1.0609 - val_accuracy: 0.8296\n",
            "Epoch 78/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0655 - accuracy: 0.9784 - val_loss: 0.9813 - val_accuracy: 0.8522\n",
            "Epoch 79/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0505 - accuracy: 0.9816 - val_loss: 0.8533 - val_accuracy: 0.8627\n",
            "Epoch 80/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0493 - accuracy: 0.9844 - val_loss: 0.8058 - val_accuracy: 0.8522\n",
            "Epoch 81/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 0.8387 - val_accuracy: 0.8477\n",
            "Epoch 82/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0517 - accuracy: 0.9841 - val_loss: 1.0321 - val_accuracy: 0.8612\n",
            "Epoch 83/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 0.9525 - val_accuracy: 0.8522\n",
            "Epoch 84/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0519 - accuracy: 0.9827 - val_loss: 0.8726 - val_accuracy: 0.8612\n",
            "Epoch 85/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0409 - accuracy: 0.9864 - val_loss: 1.0342 - val_accuracy: 0.8673\n",
            "Epoch 86/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0467 - accuracy: 0.9846 - val_loss: 0.9508 - val_accuracy: 0.8612\n",
            "Epoch 87/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0542 - accuracy: 0.9804 - val_loss: 1.0183 - val_accuracy: 0.8582\n",
            "Epoch 88/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0531 - accuracy: 0.9832 - val_loss: 0.7994 - val_accuracy: 0.8492\n",
            "Epoch 89/400\n",
            "120/120 [==============================] - 2s 20ms/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 1.0657 - val_accuracy: 0.8552\n",
            "Epoch 90/400\n",
            "120/120 [==============================] - 2s 20ms/step - loss: 0.0652 - accuracy: 0.9807 - val_loss: 0.7409 - val_accuracy: 0.8612\n",
            "Epoch 91/400\n",
            "120/120 [==============================] - 2s 20ms/step - loss: 0.0589 - accuracy: 0.9807 - val_loss: 0.8218 - val_accuracy: 0.8537\n",
            "Epoch 92/400\n",
            "120/120 [==============================] - 2s 20ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 0.9437 - val_accuracy: 0.8658\n",
            "Epoch 93/400\n",
            "120/120 [==============================] - 2s 20ms/step - loss: 0.0515 - accuracy: 0.9834 - val_loss: 0.9406 - val_accuracy: 0.8718\n",
            "Epoch 94/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0645 - accuracy: 0.9822 - val_loss: 0.7284 - val_accuracy: 0.8673\n",
            "Epoch 95/400\n",
            "120/120 [==============================] - 2s 21ms/step - loss: 0.0406 - accuracy: 0.9834 - val_loss: 0.9888 - val_accuracy: 0.8688\n",
            "Epoch 96/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 0.9079 - val_accuracy: 0.8522\n",
            "Epoch 97/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0508 - accuracy: 0.9864 - val_loss: 0.9609 - val_accuracy: 0.8582\n",
            "Epoch 98/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0483 - accuracy: 0.9836 - val_loss: 1.0403 - val_accuracy: 0.8612\n",
            "Epoch 99/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.9356 - val_accuracy: 0.8808\n",
            "Epoch 100/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0570 - accuracy: 0.9809 - val_loss: 0.8580 - val_accuracy: 0.8522\n",
            "Epoch 101/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0517 - accuracy: 0.9827 - val_loss: 1.0247 - val_accuracy: 0.8462\n",
            "Epoch 102/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0625 - accuracy: 0.9811 - val_loss: 0.7434 - val_accuracy: 0.8537\n",
            "Epoch 103/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0497 - accuracy: 0.9837 - val_loss: 0.7985 - val_accuracy: 0.8507\n",
            "Epoch 104/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0537 - accuracy: 0.9824 - val_loss: 0.8832 - val_accuracy: 0.8371\n",
            "Epoch 105/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.9731 - val_accuracy: 0.8537\n",
            "Epoch 106/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0432 - accuracy: 0.9851 - val_loss: 0.9705 - val_accuracy: 0.8507\n",
            "Epoch 107/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0412 - accuracy: 0.9851 - val_loss: 1.2412 - val_accuracy: 0.8386\n",
            "Epoch 108/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 0.9284 - val_accuracy: 0.8597\n",
            "Epoch 109/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 0.9405 - val_accuracy: 0.8673\n",
            "Epoch 110/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0468 - accuracy: 0.9844 - val_loss: 0.9630 - val_accuracy: 0.8627\n",
            "Epoch 111/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0386 - accuracy: 0.9871 - val_loss: 1.1747 - val_accuracy: 0.8612\n",
            "Epoch 112/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0513 - accuracy: 0.9849 - val_loss: 0.8260 - val_accuracy: 0.8597\n",
            "Epoch 113/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0367 - accuracy: 0.9869 - val_loss: 0.9801 - val_accuracy: 0.8582\n",
            "Epoch 114/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 1.0794 - val_accuracy: 0.8567\n",
            "Epoch 115/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0436 - accuracy: 0.9857 - val_loss: 0.9714 - val_accuracy: 0.8567\n",
            "Epoch 116/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0519 - accuracy: 0.9816 - val_loss: 0.9181 - val_accuracy: 0.8688\n",
            "Epoch 117/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0428 - accuracy: 0.9859 - val_loss: 1.0245 - val_accuracy: 0.8446\n",
            "Epoch 118/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0364 - accuracy: 0.9863 - val_loss: 0.8751 - val_accuracy: 0.8612\n",
            "Epoch 119/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 1.1171 - val_accuracy: 0.8597\n",
            "Epoch 120/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0422 - accuracy: 0.9854 - val_loss: 0.9440 - val_accuracy: 0.8703\n",
            "Epoch 121/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0359 - accuracy: 0.9868 - val_loss: 1.0194 - val_accuracy: 0.8582\n",
            "Epoch 122/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0369 - accuracy: 0.9876 - val_loss: 0.9455 - val_accuracy: 0.8793\n",
            "Epoch 123/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0336 - accuracy: 0.9889 - val_loss: 1.0305 - val_accuracy: 0.8658\n",
            "Epoch 124/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0406 - accuracy: 0.9873 - val_loss: 1.0575 - val_accuracy: 0.8612\n",
            "Epoch 125/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0399 - accuracy: 0.9888 - val_loss: 0.9361 - val_accuracy: 0.8703\n",
            "Epoch 126/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0630 - accuracy: 0.9837 - val_loss: 0.8310 - val_accuracy: 0.8643\n",
            "Epoch 127/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0607 - accuracy: 0.9836 - val_loss: 0.9176 - val_accuracy: 0.8673\n",
            "Epoch 128/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0543 - accuracy: 0.9841 - val_loss: 0.8485 - val_accuracy: 0.8673\n",
            "Epoch 129/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0422 - accuracy: 0.9859 - val_loss: 0.9458 - val_accuracy: 0.8597\n",
            "Epoch 130/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 1.1643 - val_accuracy: 0.8567\n",
            "Epoch 131/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0385 - accuracy: 0.9854 - val_loss: 0.9428 - val_accuracy: 0.8854\n",
            "Epoch 132/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0402 - accuracy: 0.9903 - val_loss: 1.0909 - val_accuracy: 0.8718\n",
            "Epoch 133/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0451 - accuracy: 0.9878 - val_loss: 0.8458 - val_accuracy: 0.8718\n",
            "Epoch 134/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0494 - accuracy: 0.9849 - val_loss: 0.7814 - val_accuracy: 0.8718\n",
            "Epoch 135/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0386 - accuracy: 0.9871 - val_loss: 1.0891 - val_accuracy: 0.8673\n",
            "Epoch 136/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 1.1816 - val_accuracy: 0.8567\n",
            "Epoch 137/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0437 - accuracy: 0.9854 - val_loss: 1.1385 - val_accuracy: 0.8552\n",
            "Epoch 138/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 1.0883 - val_accuracy: 0.8492\n",
            "Epoch 139/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0360 - accuracy: 0.9869 - val_loss: 1.0418 - val_accuracy: 0.8582\n",
            "Epoch 140/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0348 - accuracy: 0.9906 - val_loss: 1.1025 - val_accuracy: 0.8522\n",
            "Epoch 141/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 1.1033 - val_accuracy: 0.8552\n",
            "Epoch 142/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0429 - accuracy: 0.9873 - val_loss: 0.9180 - val_accuracy: 0.8552\n",
            "Epoch 143/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0317 - accuracy: 0.9916 - val_loss: 1.1368 - val_accuracy: 0.8627\n",
            "Epoch 144/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0381 - accuracy: 0.9894 - val_loss: 0.9401 - val_accuracy: 0.8567\n",
            "Epoch 145/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0305 - accuracy: 0.9913 - val_loss: 1.2094 - val_accuracy: 0.8462\n",
            "Epoch 146/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0521 - accuracy: 0.9874 - val_loss: 0.9094 - val_accuracy: 0.8492\n",
            "Epoch 147/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 1.0281 - val_accuracy: 0.8567\n",
            "Epoch 148/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0312 - accuracy: 0.9909 - val_loss: 1.1652 - val_accuracy: 0.8612\n",
            "Epoch 149/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 1.0772 - val_accuracy: 0.8597\n",
            "Epoch 150/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 1.0589 - val_accuracy: 0.8492\n",
            "Epoch 151/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0468 - accuracy: 0.9869 - val_loss: 0.9821 - val_accuracy: 0.8703\n",
            "Epoch 152/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0363 - accuracy: 0.9901 - val_loss: 0.9481 - val_accuracy: 0.8597\n",
            "Epoch 153/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0472 - accuracy: 0.9869 - val_loss: 0.9305 - val_accuracy: 0.8567\n",
            "Epoch 154/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0400 - accuracy: 0.9878 - val_loss: 1.3397 - val_accuracy: 0.8612\n",
            "Epoch 155/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0427 - accuracy: 0.9863 - val_loss: 0.9444 - val_accuracy: 0.8627\n",
            "Epoch 156/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0424 - accuracy: 0.9879 - val_loss: 0.9033 - val_accuracy: 0.8597\n",
            "Epoch 157/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 1.0148 - val_accuracy: 0.8612\n",
            "Epoch 158/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 1.0491 - val_accuracy: 0.8567\n",
            "Epoch 159/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0326 - accuracy: 0.9876 - val_loss: 1.1368 - val_accuracy: 0.8643\n",
            "Epoch 160/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0363 - accuracy: 0.9873 - val_loss: 1.1302 - val_accuracy: 0.8537\n",
            "Epoch 161/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0314 - accuracy: 0.9913 - val_loss: 1.1686 - val_accuracy: 0.8627\n",
            "Epoch 162/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0412 - accuracy: 0.9888 - val_loss: 0.9348 - val_accuracy: 0.8673\n",
            "Epoch 163/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 1.0536 - val_accuracy: 0.8658\n",
            "Epoch 164/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0271 - accuracy: 0.9901 - val_loss: 1.2020 - val_accuracy: 0.8718\n",
            "Epoch 165/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0355 - accuracy: 0.9879 - val_loss: 0.9806 - val_accuracy: 0.8537\n",
            "Epoch 166/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0293 - accuracy: 0.9920 - val_loss: 1.1520 - val_accuracy: 0.8522\n",
            "Epoch 167/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 0.9430 - val_accuracy: 0.8733\n",
            "Epoch 168/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 1.1702 - val_accuracy: 0.8612\n",
            "Epoch 169/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0436 - accuracy: 0.9854 - val_loss: 1.0165 - val_accuracy: 0.8492\n",
            "Epoch 170/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0337 - accuracy: 0.9881 - val_loss: 1.0683 - val_accuracy: 0.8612\n",
            "Epoch 171/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 1.2055 - val_accuracy: 0.8658\n",
            "Epoch 172/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0307 - accuracy: 0.9899 - val_loss: 0.9875 - val_accuracy: 0.8507\n",
            "Epoch 173/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 1.2285 - val_accuracy: 0.8567\n",
            "Epoch 174/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0317 - accuracy: 0.9898 - val_loss: 1.4154 - val_accuracy: 0.8507\n",
            "Epoch 175/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 1.3092 - val_accuracy: 0.8643\n",
            "Epoch 176/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0361 - accuracy: 0.9898 - val_loss: 1.2061 - val_accuracy: 0.8673\n",
            "Epoch 177/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 1.2892 - val_accuracy: 0.8582\n",
            "Epoch 178/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 1.2061 - val_accuracy: 0.8718\n",
            "Epoch 179/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 1.1677 - val_accuracy: 0.8733\n",
            "Epoch 180/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 1.2614 - val_accuracy: 0.8492\n",
            "Epoch 181/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 1.2034 - val_accuracy: 0.8658\n",
            "Epoch 182/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0365 - accuracy: 0.9903 - val_loss: 1.0973 - val_accuracy: 0.8582\n",
            "Epoch 183/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0342 - accuracy: 0.9906 - val_loss: 1.0206 - val_accuracy: 0.8643\n",
            "Epoch 184/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0291 - accuracy: 0.9901 - val_loss: 1.1052 - val_accuracy: 0.8658\n",
            "Epoch 185/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0320 - accuracy: 0.9909 - val_loss: 1.0857 - val_accuracy: 0.8597\n",
            "Epoch 186/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 1.0648 - val_accuracy: 0.8643\n",
            "Epoch 187/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0256 - accuracy: 0.9935 - val_loss: 1.2143 - val_accuracy: 0.8627\n",
            "Epoch 188/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0352 - accuracy: 0.9918 - val_loss: 1.1004 - val_accuracy: 0.8537\n",
            "Epoch 189/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 1.0654 - val_accuracy: 0.8627\n",
            "Epoch 190/400\n",
            "120/120 [==============================] - 3s 24ms/step - loss: 0.0406 - accuracy: 0.9896 - val_loss: 1.0295 - val_accuracy: 0.8492\n",
            "Epoch 191/400\n",
            "120/120 [==============================] - 3s 24ms/step - loss: 0.0320 - accuracy: 0.9913 - val_loss: 1.2132 - val_accuracy: 0.8688\n",
            "Epoch 192/400\n",
            "120/120 [==============================] - 3s 24ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 1.2507 - val_accuracy: 0.8477\n",
            "Epoch 193/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0389 - accuracy: 0.9893 - val_loss: 1.2504 - val_accuracy: 0.8597\n",
            "Epoch 194/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 1.3898 - val_accuracy: 0.8627\n",
            "Epoch 195/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0287 - accuracy: 0.9931 - val_loss: 1.3276 - val_accuracy: 0.8567\n",
            "Epoch 196/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 1.4626 - val_accuracy: 0.8552\n",
            "Epoch 197/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0382 - accuracy: 0.9891 - val_loss: 0.9609 - val_accuracy: 0.8567\n",
            "Epoch 198/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0327 - accuracy: 0.9913 - val_loss: 1.0765 - val_accuracy: 0.8477\n",
            "Epoch 199/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 1.0394 - val_accuracy: 0.8537\n",
            "Epoch 200/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0337 - accuracy: 0.9911 - val_loss: 1.3103 - val_accuracy: 0.8612\n",
            "Epoch 201/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 1.2425 - val_accuracy: 0.8552\n",
            "Epoch 202/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0240 - accuracy: 0.9941 - val_loss: 1.1721 - val_accuracy: 0.8658\n",
            "Epoch 203/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0351 - accuracy: 0.9906 - val_loss: 1.0409 - val_accuracy: 0.8597\n",
            "Epoch 204/400\n",
            "120/120 [==============================] - 3s 25ms/step - loss: 0.0390 - accuracy: 0.9899 - val_loss: 0.9337 - val_accuracy: 0.8643\n",
            "Epoch 205/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 1.0016 - val_accuracy: 0.8597\n",
            "Epoch 206/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0341 - accuracy: 0.9898 - val_loss: 1.0892 - val_accuracy: 0.8492\n",
            "Epoch 207/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0282 - accuracy: 0.9896 - val_loss: 1.0387 - val_accuracy: 0.8612\n",
            "Epoch 208/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0261 - accuracy: 0.9931 - val_loss: 1.2294 - val_accuracy: 0.8582\n",
            "Epoch 209/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0265 - accuracy: 0.9925 - val_loss: 1.2095 - val_accuracy: 0.8582\n",
            "Epoch 210/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0305 - accuracy: 0.9916 - val_loss: 1.0996 - val_accuracy: 0.8522\n",
            "Epoch 211/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 1.1326 - val_accuracy: 0.8582\n",
            "Epoch 212/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0288 - accuracy: 0.9894 - val_loss: 1.2840 - val_accuracy: 0.8703\n",
            "Epoch 213/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 1.1417 - val_accuracy: 0.8673\n",
            "Epoch 214/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 1.1689 - val_accuracy: 0.8703\n",
            "Epoch 215/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 1.2915 - val_accuracy: 0.8793\n",
            "Epoch 216/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 1.2653 - val_accuracy: 0.8597\n",
            "Epoch 217/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 1.2550 - val_accuracy: 0.8477\n",
            "Epoch 218/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 1.4490 - val_accuracy: 0.8658\n",
            "Epoch 219/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 1.0976 - val_accuracy: 0.8718\n",
            "Epoch 220/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0440 - accuracy: 0.9911 - val_loss: 1.1310 - val_accuracy: 0.8748\n",
            "Epoch 221/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0380 - accuracy: 0.9906 - val_loss: 1.1591 - val_accuracy: 0.8552\n",
            "Epoch 222/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0338 - accuracy: 0.9918 - val_loss: 1.1117 - val_accuracy: 0.8673\n",
            "Epoch 223/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0329 - accuracy: 0.9906 - val_loss: 0.9160 - val_accuracy: 0.8763\n",
            "Epoch 224/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 1.2074 - val_accuracy: 0.8627\n",
            "Epoch 225/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0397 - accuracy: 0.9891 - val_loss: 1.1839 - val_accuracy: 0.8597\n",
            "Epoch 226/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 1.1533 - val_accuracy: 0.8567\n",
            "Epoch 227/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.4478 - val_accuracy: 0.8582\n",
            "Epoch 228/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0335 - accuracy: 0.9906 - val_loss: 1.0860 - val_accuracy: 0.8673\n",
            "Epoch 229/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 1.3610 - val_accuracy: 0.8612\n",
            "Epoch 230/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 1.4758 - val_accuracy: 0.8688\n",
            "Epoch 231/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0306 - accuracy: 0.9913 - val_loss: 1.2663 - val_accuracy: 0.8884\n",
            "Epoch 232/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0347 - accuracy: 0.9913 - val_loss: 1.0970 - val_accuracy: 0.8733\n",
            "Epoch 233/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 1.1259 - val_accuracy: 0.8718\n",
            "Epoch 234/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0228 - accuracy: 0.9940 - val_loss: 1.0916 - val_accuracy: 0.8748\n",
            "Epoch 235/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 1.2293 - val_accuracy: 0.8688\n",
            "Epoch 236/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0337 - accuracy: 0.9898 - val_loss: 1.0884 - val_accuracy: 0.8763\n",
            "Epoch 237/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0278 - accuracy: 0.9920 - val_loss: 0.9829 - val_accuracy: 0.8718\n",
            "Epoch 238/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 1.3172 - val_accuracy: 0.8748\n",
            "Epoch 239/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0301 - accuracy: 0.9920 - val_loss: 1.0369 - val_accuracy: 0.8673\n",
            "Epoch 240/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0398 - accuracy: 0.9884 - val_loss: 1.1598 - val_accuracy: 0.8703\n",
            "Epoch 241/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 1.2765 - val_accuracy: 0.8627\n",
            "Epoch 242/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0236 - accuracy: 0.9916 - val_loss: 1.3403 - val_accuracy: 0.8718\n",
            "Epoch 243/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0209 - accuracy: 0.9913 - val_loss: 1.3421 - val_accuracy: 0.8748\n",
            "Epoch 244/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 1.2877 - val_accuracy: 0.8582\n",
            "Epoch 245/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 1.0721 - val_accuracy: 0.8673\n",
            "Epoch 246/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 1.1690 - val_accuracy: 0.8688\n",
            "Epoch 247/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 1.4608 - val_accuracy: 0.8673\n",
            "Epoch 248/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 1.4708 - val_accuracy: 0.8477\n",
            "Epoch 249/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0368 - accuracy: 0.9899 - val_loss: 1.6012 - val_accuracy: 0.8658\n",
            "Epoch 250/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 1.5123 - val_accuracy: 0.8673\n",
            "Epoch 251/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0295 - accuracy: 0.9916 - val_loss: 1.1888 - val_accuracy: 0.8627\n",
            "Epoch 252/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 1.8179 - val_accuracy: 0.8643\n",
            "Epoch 253/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0478 - accuracy: 0.9901 - val_loss: 1.0948 - val_accuracy: 0.8718\n",
            "Epoch 254/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0391 - accuracy: 0.9891 - val_loss: 1.2403 - val_accuracy: 0.8703\n",
            "Epoch 255/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 1.4426 - val_accuracy: 0.8597\n",
            "Epoch 256/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 1.6456 - val_accuracy: 0.8748\n",
            "Epoch 257/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 1.1415 - val_accuracy: 0.8718\n",
            "Epoch 258/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 1.2354 - val_accuracy: 0.8763\n",
            "Epoch 259/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0270 - accuracy: 0.9894 - val_loss: 1.0850 - val_accuracy: 0.8748\n",
            "Epoch 260/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 1.1751 - val_accuracy: 0.8703\n",
            "Epoch 261/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 1.2175 - val_accuracy: 0.8718\n",
            "Epoch 262/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0419 - accuracy: 0.9886 - val_loss: 1.0027 - val_accuracy: 0.8718\n",
            "Epoch 263/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 1.3718 - val_accuracy: 0.8582\n",
            "Epoch 264/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 1.4116 - val_accuracy: 0.8733\n",
            "Epoch 265/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 1.4000 - val_accuracy: 0.8643\n",
            "Epoch 266/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0198 - accuracy: 0.9946 - val_loss: 1.6154 - val_accuracy: 0.8627\n",
            "Epoch 267/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0335 - accuracy: 0.9909 - val_loss: 1.0603 - val_accuracy: 0.8793\n",
            "Epoch 268/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0408 - accuracy: 0.9899 - val_loss: 0.9847 - val_accuracy: 0.8673\n",
            "Epoch 269/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0251 - accuracy: 0.9930 - val_loss: 1.5724 - val_accuracy: 0.8718\n",
            "Epoch 270/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0344 - accuracy: 0.9911 - val_loss: 1.1704 - val_accuracy: 0.8688\n",
            "Epoch 271/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 1.2995 - val_accuracy: 0.8643\n",
            "Epoch 272/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 1.2756 - val_accuracy: 0.8733\n",
            "Epoch 273/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 1.4599 - val_accuracy: 0.8778\n",
            "Epoch 274/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 1.2065 - val_accuracy: 0.8763\n",
            "Epoch 275/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 1.3135 - val_accuracy: 0.8763\n",
            "Epoch 276/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 1.4043 - val_accuracy: 0.8688\n",
            "Epoch 277/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 1.3606 - val_accuracy: 0.8748\n",
            "Epoch 278/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0314 - accuracy: 0.9903 - val_loss: 1.0482 - val_accuracy: 0.8688\n",
            "Epoch 279/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 1.2305 - val_accuracy: 0.8778\n",
            "Epoch 280/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 1.3497 - val_accuracy: 0.8733\n",
            "Epoch 281/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 1.4238 - val_accuracy: 0.8748\n",
            "Epoch 282/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 1.3838 - val_accuracy: 0.8552\n",
            "Epoch 283/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0196 - accuracy: 0.9951 - val_loss: 1.2562 - val_accuracy: 0.8733\n",
            "Epoch 284/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0335 - accuracy: 0.9921 - val_loss: 1.1596 - val_accuracy: 0.8492\n",
            "Epoch 285/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0227 - accuracy: 0.9935 - val_loss: 1.4916 - val_accuracy: 0.8688\n",
            "Epoch 286/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0361 - accuracy: 0.9901 - val_loss: 1.0939 - val_accuracy: 0.8673\n",
            "Epoch 287/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0312 - accuracy: 0.9925 - val_loss: 1.1338 - val_accuracy: 0.8688\n",
            "Epoch 288/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0301 - accuracy: 0.9913 - val_loss: 1.3101 - val_accuracy: 0.8658\n",
            "Epoch 289/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 1.2394 - val_accuracy: 0.8793\n",
            "Epoch 290/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0296 - accuracy: 0.9933 - val_loss: 0.9622 - val_accuracy: 0.8658\n",
            "Epoch 291/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 1.2015 - val_accuracy: 0.8688\n",
            "Epoch 292/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 1.3972 - val_accuracy: 0.8612\n",
            "Epoch 293/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 1.3409 - val_accuracy: 0.8733\n",
            "Epoch 294/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0322 - accuracy: 0.9918 - val_loss: 1.0644 - val_accuracy: 0.8643\n",
            "Epoch 295/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0233 - accuracy: 0.9918 - val_loss: 1.1411 - val_accuracy: 0.8612\n",
            "Epoch 296/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 1.5845 - val_accuracy: 0.8763\n",
            "Epoch 297/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0317 - accuracy: 0.9936 - val_loss: 1.1459 - val_accuracy: 0.8778\n",
            "Epoch 298/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 1.2385 - val_accuracy: 0.8658\n",
            "Epoch 299/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 1.3229 - val_accuracy: 0.8703\n",
            "Epoch 300/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0219 - accuracy: 0.9928 - val_loss: 1.3850 - val_accuracy: 0.8673\n",
            "Epoch 301/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0214 - accuracy: 0.9940 - val_loss: 1.6031 - val_accuracy: 0.8793\n",
            "Epoch 302/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0257 - accuracy: 0.9926 - val_loss: 1.4248 - val_accuracy: 0.8748\n",
            "Epoch 303/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 1.3937 - val_accuracy: 0.8733\n",
            "Epoch 304/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0352 - accuracy: 0.9921 - val_loss: 1.0663 - val_accuracy: 0.8567\n",
            "Epoch 305/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 1.4880 - val_accuracy: 0.8778\n",
            "Epoch 306/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0331 - accuracy: 0.9925 - val_loss: 1.0958 - val_accuracy: 0.8703\n",
            "Epoch 307/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0296 - accuracy: 0.9914 - val_loss: 1.2043 - val_accuracy: 0.8718\n",
            "Epoch 308/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0284 - accuracy: 0.9935 - val_loss: 1.2291 - val_accuracy: 0.8733\n",
            "Epoch 309/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 1.4167 - val_accuracy: 0.8597\n",
            "Epoch 310/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0261 - accuracy: 0.9941 - val_loss: 1.2911 - val_accuracy: 0.8612\n",
            "Epoch 311/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0308 - accuracy: 0.9931 - val_loss: 1.0166 - val_accuracy: 0.8567\n",
            "Epoch 312/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0314 - accuracy: 0.9918 - val_loss: 1.0694 - val_accuracy: 0.8643\n",
            "Epoch 313/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 1.3117 - val_accuracy: 0.8688\n",
            "Epoch 314/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 1.2702 - val_accuracy: 0.8763\n",
            "Epoch 315/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0154 - accuracy: 0.9941 - val_loss: 1.5267 - val_accuracy: 0.8688\n",
            "Epoch 316/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 1.3452 - val_accuracy: 0.8658\n",
            "Epoch 317/400\n",
            "120/120 [==============================] - 3s 23ms/step - loss: 0.0284 - accuracy: 0.9931 - val_loss: 1.5418 - val_accuracy: 0.8643\n",
            "Epoch 318/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0247 - accuracy: 0.9930 - val_loss: 1.3665 - val_accuracy: 0.8763\n",
            "Epoch 319/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 1.2625 - val_accuracy: 0.8643\n",
            "Epoch 320/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 1.5760 - val_accuracy: 0.8552\n",
            "Epoch 321/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0246 - accuracy: 0.9948 - val_loss: 1.0882 - val_accuracy: 0.8808\n",
            "Epoch 322/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 1.2928 - val_accuracy: 0.8597\n",
            "Epoch 323/400\n",
            "120/120 [==============================] - 3s 22ms/step - loss: 0.0349 - accuracy: 0.9936 - val_loss: 1.1849 - val_accuracy: 0.8703\n",
            "Epoch 324/400\n",
            "120/120 [==============================] - 3s 21ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 1.1649 - val_accuracy: 0.8763\n",
            "Epoch 325/400\n",
            "120/120 [==============================] - 2s 20ms/step - loss: 0.0354 - accuracy: 0.9909 - val_loss: 1.0805 - val_accuracy: 0.8658\n",
            "Epoch 326/400\n",
            "120/120 [==============================] - 2s 20ms/step - loss: 0.0338 - accuracy: 0.9914 - val_loss: 1.1216 - val_accuracy: 0.8688\n",
            "Epoch 327/400\n",
            "120/120 [==============================] - 2s 20ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 1.2201 - val_accuracy: 0.8793\n",
            "Epoch 328/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0221 - accuracy: 0.9951 - val_loss: 1.3327 - val_accuracy: 0.8627\n",
            "Epoch 329/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 1.4772 - val_accuracy: 0.8793\n",
            "Epoch 330/400\n",
            "120/120 [==============================] - 2s 19ms/step - loss: 0.0246 - accuracy: 0.9945 - val_loss: 1.4349 - val_accuracy: 0.8733\n",
            "Epoch 331/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0232 - accuracy: 0.9946 - val_loss: 1.3808 - val_accuracy: 0.8688\n",
            "Epoch 332/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0182 - accuracy: 0.9935 - val_loss: 1.4768 - val_accuracy: 0.8733\n",
            "Epoch 333/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0202 - accuracy: 0.9946 - val_loss: 1.7113 - val_accuracy: 0.8703\n",
            "Epoch 334/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0334 - accuracy: 0.9899 - val_loss: 1.2061 - val_accuracy: 0.8703\n",
            "Epoch 335/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 1.4810 - val_accuracy: 0.8658\n",
            "Epoch 336/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 1.3462 - val_accuracy: 0.8703\n",
            "Epoch 337/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0317 - accuracy: 0.9930 - val_loss: 1.5092 - val_accuracy: 0.8793\n",
            "Epoch 338/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0316 - accuracy: 0.9920 - val_loss: 1.1218 - val_accuracy: 0.8748\n",
            "Epoch 339/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 1.6351 - val_accuracy: 0.8673\n",
            "Epoch 340/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 1.7097 - val_accuracy: 0.8673\n",
            "Epoch 341/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0251 - accuracy: 0.9943 - val_loss: 1.4874 - val_accuracy: 0.8612\n",
            "Epoch 342/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 1.7914 - val_accuracy: 0.8688\n",
            "Epoch 343/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 1.9038 - val_accuracy: 0.8567\n",
            "Epoch 344/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 1.7737 - val_accuracy: 0.8673\n",
            "Epoch 345/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0306 - accuracy: 0.9930 - val_loss: 1.3649 - val_accuracy: 0.8567\n",
            "Epoch 346/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0322 - accuracy: 0.9911 - val_loss: 1.5991 - val_accuracy: 0.8703\n",
            "Epoch 347/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 1.5328 - val_accuracy: 0.8673\n",
            "Epoch 348/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 1.2583 - val_accuracy: 0.8718\n",
            "Epoch 349/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 1.2562 - val_accuracy: 0.8733\n",
            "Epoch 350/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 1.3665 - val_accuracy: 0.8658\n",
            "Epoch 351/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0220 - accuracy: 0.9946 - val_loss: 1.4561 - val_accuracy: 0.8688\n",
            "Epoch 352/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0465 - accuracy: 0.9909 - val_loss: 1.3172 - val_accuracy: 0.8673\n",
            "Epoch 353/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 1.4746 - val_accuracy: 0.8718\n",
            "Epoch 354/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 1.8548 - val_accuracy: 0.8582\n",
            "Epoch 355/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0155 - accuracy: 0.9938 - val_loss: 1.6632 - val_accuracy: 0.8643\n",
            "Epoch 356/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0304 - accuracy: 0.9930 - val_loss: 1.3969 - val_accuracy: 0.8793\n",
            "Epoch 357/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0301 - accuracy: 0.9941 - val_loss: 1.4137 - val_accuracy: 0.8718\n",
            "Epoch 358/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 1.8934 - val_accuracy: 0.8703\n",
            "Epoch 359/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 1.5027 - val_accuracy: 0.8748\n",
            "Epoch 360/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 1.5342 - val_accuracy: 0.8733\n",
            "Epoch 361/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 1.6360 - val_accuracy: 0.8733\n",
            "Epoch 362/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 1.7479 - val_accuracy: 0.8658\n",
            "Epoch 363/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 1.3695 - val_accuracy: 0.8778\n",
            "Epoch 364/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 1.5151 - val_accuracy: 0.8748\n",
            "Epoch 365/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 1.5990 - val_accuracy: 0.8673\n",
            "Epoch 366/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 1.9657 - val_accuracy: 0.8673\n",
            "Epoch 367/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0395 - accuracy: 0.9923 - val_loss: 1.5245 - val_accuracy: 0.8658\n",
            "Epoch 368/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0320 - accuracy: 0.9923 - val_loss: 1.3339 - val_accuracy: 0.8597\n",
            "Epoch 369/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0369 - accuracy: 0.9921 - val_loss: 1.7350 - val_accuracy: 0.8673\n",
            "Epoch 370/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 1.4432 - val_accuracy: 0.8643\n",
            "Epoch 371/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0260 - accuracy: 0.9948 - val_loss: 1.5574 - val_accuracy: 0.8718\n",
            "Epoch 372/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 1.8360 - val_accuracy: 0.8808\n",
            "Epoch 373/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0262 - accuracy: 0.9941 - val_loss: 1.2556 - val_accuracy: 0.8793\n",
            "Epoch 374/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0335 - accuracy: 0.9914 - val_loss: 1.2736 - val_accuracy: 0.8658\n",
            "Epoch 375/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0214 - accuracy: 0.9945 - val_loss: 1.3942 - val_accuracy: 0.8643\n",
            "Epoch 376/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 1.8823 - val_accuracy: 0.8658\n",
            "Epoch 377/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 1.8711 - val_accuracy: 0.8643\n",
            "Epoch 378/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0214 - accuracy: 0.9955 - val_loss: 1.6441 - val_accuracy: 0.8718\n",
            "Epoch 379/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 1.5416 - val_accuracy: 0.8733\n",
            "Epoch 380/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 1.5509 - val_accuracy: 0.8778\n",
            "Epoch 381/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0208 - accuracy: 0.9946 - val_loss: 1.4598 - val_accuracy: 0.8854\n",
            "Epoch 382/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 1.9505 - val_accuracy: 0.8658\n",
            "Epoch 383/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0331 - accuracy: 0.9935 - val_loss: 1.3929 - val_accuracy: 0.8658\n",
            "Epoch 384/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0182 - accuracy: 0.9948 - val_loss: 1.5355 - val_accuracy: 0.8673\n",
            "Epoch 385/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 1.6992 - val_accuracy: 0.8748\n",
            "Epoch 386/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0315 - accuracy: 0.9923 - val_loss: 1.5298 - val_accuracy: 0.8658\n",
            "Epoch 387/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 1.5486 - val_accuracy: 0.8778\n",
            "Epoch 388/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 1.7914 - val_accuracy: 0.8718\n",
            "Epoch 389/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0281 - accuracy: 0.9928 - val_loss: 1.5829 - val_accuracy: 0.8673\n",
            "Epoch 390/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0156 - accuracy: 0.9941 - val_loss: 1.7002 - val_accuracy: 0.8703\n",
            "Epoch 391/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0280 - accuracy: 0.9935 - val_loss: 1.2734 - val_accuracy: 0.8567\n",
            "Epoch 392/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0330 - accuracy: 0.9901 - val_loss: 1.3763 - val_accuracy: 0.8688\n",
            "Epoch 393/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 1.5505 - val_accuracy: 0.8778\n",
            "Epoch 394/400\n",
            "120/120 [==============================] - 2s 18ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 1.8400 - val_accuracy: 0.8612\n",
            "Epoch 395/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 1.8516 - val_accuracy: 0.8718\n",
            "Epoch 396/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0130 - accuracy: 0.9975 - val_loss: 1.9387 - val_accuracy: 0.8763\n",
            "Epoch 397/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 1.8036 - val_accuracy: 0.8703\n",
            "Epoch 398/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0269 - accuracy: 0.9950 - val_loss: 1.5213 - val_accuracy: 0.8673\n",
            "Epoch 399/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0172 - accuracy: 0.9935 - val_loss: 2.0854 - val_accuracy: 0.8703\n",
            "Epoch 400/400\n",
            "120/120 [==============================] - 2s 17ms/step - loss: 0.0295 - accuracy: 0.9928 - val_loss: 1.4587 - val_accuracy: 0.8552\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs = 400, validation_data = (X_test, y_test), batch_size = 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eJQT9WqOTxAm"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('predict_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "later_model = load_model('predict_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "losses.plot()\n",
        "plt.savefig('losses.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Marital status                                       1.000000\n",
              "Application mode                                    17.000000\n",
              "Application order                                    1.000000\n",
              "Course                                            9853.000000\n",
              "Daytime/evening attendance                           1.000000\n",
              "Previous qualification                               1.000000\n",
              "Previous qualification (grade)                     125.000000\n",
              "Nacionality                                          1.000000\n",
              "Mother's qualification                              19.000000\n",
              "Father's qualification                              19.000000\n",
              "Mother's occupation                                  4.000000\n",
              "Father's occupation                                  7.000000\n",
              "Admission grade                                    128.500000\n",
              "Displaced                                            1.000000\n",
              "Educational special needs                            0.000000\n",
              "Debtor                                               0.000000\n",
              "Tuition fees up to date                              1.000000\n",
              "Gender                                               0.000000\n",
              "Scholarship holder                                   0.000000\n",
              "Age at enrollment                                   18.000000\n",
              "International                                        0.000000\n",
              "Curricular units 1st sem (credited)                  0.000000\n",
              "Curricular units 1st sem (enrolled)                  7.000000\n",
              "Curricular units 1st sem (evaluations)               9.000000\n",
              "Curricular units 1st sem (approved)                  6.000000\n",
              "Curricular units 1st sem (grade)                    11.500000\n",
              "Curricular units 1st sem (without evaluations)       0.000000\n",
              "Curricular units 2nd sem (credited)                  0.000000\n",
              "Curricular units 2nd sem (enrolled)                  7.000000\n",
              "Curricular units 2nd sem (evaluations)               8.000000\n",
              "Curricular units 2nd sem (approved)                  7.000000\n",
              "Curricular units 2nd sem (grade)                    12.714286\n",
              "Curricular units 2nd sem (without evaluations)       0.000000\n",
              "Unemployment rate                                   13.900000\n",
              "Inflation rate                                      -0.300000\n",
              "GDP                                                  0.790000\n",
              "Name: 1195, dtype: float64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "random.seed(87)\n",
        "random_ind = random.randint(0, len(dataset))\n",
        "\n",
        "new_student = dataset.drop('Target',axis = 1).iloc[random_ind]\n",
        "new_student"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 107ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1, 0, 0]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(model.predict(new_student.values.reshape(1,36)) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Enrolled'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.iloc[random_ind]['Target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.8552036199095022\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.81      0.86       221\n",
            "           1       0.80      0.92      0.86       211\n",
            "           2       0.89      0.84      0.86       231\n",
            "\n",
            "   micro avg       0.86      0.86      0.86       663\n",
            "   macro avg       0.87      0.86      0.86       663\n",
            "weighted avg       0.87      0.86      0.86       663\n",
            " samples avg       0.86      0.86      0.86       663\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy Score:', accuracy_score(y_test, predictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test, predictions))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
