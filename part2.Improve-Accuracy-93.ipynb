{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Essential Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "IBXRF3JsTKP1",
        "outputId": "560073c5-f44d-494e-9021-9921158a1b06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Previous qualification (grade)</th>\n",
              "      <th>Nacionality</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 2nd sem (credited)</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>171</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>9254</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>160.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>9070</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>9773</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-3.12</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>8014</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>9991</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>133.1</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>11.500000</td>\n",
              "      <td>5</td>\n",
              "      <td>16.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9500</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>142.0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>38</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>14.345000</td>\n",
              "      <td>0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-4.06</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>9254</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>119.0</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>-4.06</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>137.0</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>14.142857</td>\n",
              "      <td>0</td>\n",
              "      <td>16.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>-0.92</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9238</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>138.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>3.51</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Marital status  Application mode  Application order  Course  \\\n",
              "0               1                17                  5     171   \n",
              "1               1                15                  1    9254   \n",
              "2               1                 1                  5    9070   \n",
              "3               1                17                  2    9773   \n",
              "4               2                39                  1    8014   \n",
              "5               2                39                  1    9991   \n",
              "6               1                 1                  1    9500   \n",
              "7               1                18                  4    9254   \n",
              "8               1                 1                  3    9238   \n",
              "9               1                 1                  1    9238   \n",
              "\n",
              "   Daytime/evening attendance  Previous qualification  \\\n",
              "0                           1                       1   \n",
              "1                           1                       1   \n",
              "2                           1                       1   \n",
              "3                           1                       1   \n",
              "4                           0                       1   \n",
              "5                           0                      19   \n",
              "6                           1                       1   \n",
              "7                           1                       1   \n",
              "8                           1                       1   \n",
              "9                           1                       1   \n",
              "\n",
              "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
              "0                           122.0            1                      19   \n",
              "1                           160.0            1                       1   \n",
              "2                           122.0            1                      37   \n",
              "3                           122.0            1                      38   \n",
              "4                           100.0            1                      37   \n",
              "5                           133.1            1                      37   \n",
              "6                           142.0            1                      19   \n",
              "7                           119.0            1                      37   \n",
              "8                           137.0           62                       1   \n",
              "9                           138.0            1                       1   \n",
              "\n",
              "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
              "0                      12  ...                                    0   \n",
              "1                       3  ...                                    0   \n",
              "2                      37  ...                                    0   \n",
              "3                      37  ...                                    0   \n",
              "4                      38  ...                                    0   \n",
              "5                      37  ...                                    0   \n",
              "6                      38  ...                                    0   \n",
              "7                      37  ...                                    0   \n",
              "8                       1  ...                                    0   \n",
              "9                      19  ...                                    0   \n",
              "\n",
              "   Curricular units 2nd sem (enrolled)  \\\n",
              "0                                    0   \n",
              "1                                    6   \n",
              "2                                    6   \n",
              "3                                    6   \n",
              "4                                    6   \n",
              "5                                    5   \n",
              "6                                    8   \n",
              "7                                    5   \n",
              "8                                    6   \n",
              "9                                    6   \n",
              "\n",
              "   Curricular units 2nd sem (evaluations)  \\\n",
              "0                                       0   \n",
              "1                                       6   \n",
              "2                                       0   \n",
              "3                                      10   \n",
              "4                                       6   \n",
              "5                                      17   \n",
              "6                                       8   \n",
              "7                                       5   \n",
              "8                                       7   \n",
              "9                                      14   \n",
              "\n",
              "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "0                                    0                          0.000000   \n",
              "1                                    6                         13.666667   \n",
              "2                                    0                          0.000000   \n",
              "3                                    5                         12.400000   \n",
              "4                                    6                         13.000000   \n",
              "5                                    5                         11.500000   \n",
              "6                                    8                         14.345000   \n",
              "7                                    0                          0.000000   \n",
              "8                                    6                         14.142857   \n",
              "9                                    2                         13.500000   \n",
              "\n",
              "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "0                                               0               10.8   \n",
              "1                                               0               13.9   \n",
              "2                                               0               10.8   \n",
              "3                                               0                9.4   \n",
              "4                                               0               13.9   \n",
              "5                                               5               16.2   \n",
              "6                                               0               15.5   \n",
              "7                                               0               15.5   \n",
              "8                                               0               16.2   \n",
              "9                                               0                8.9   \n",
              "\n",
              "   Inflation rate   GDP    Target  \n",
              "0             1.4  1.74   Dropout  \n",
              "1            -0.3  0.79  Graduate  \n",
              "2             1.4  1.74   Dropout  \n",
              "3            -0.8 -3.12  Graduate  \n",
              "4            -0.3  0.79  Graduate  \n",
              "5             0.3 -0.92  Graduate  \n",
              "6             2.8 -4.06  Graduate  \n",
              "7             2.8 -4.06   Dropout  \n",
              "8             0.3 -0.92  Graduate  \n",
              "9             1.4  3.51   Dropout  \n",
              "\n",
              "[10 rows x 37 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#dataset import\n",
        "dataset = pd.read_csv('data.csv') #You need to change #directory accordingly\n",
        "dataset.head(10) #Return 10 rows of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-buQfLLrTUuc",
        "outputId": "a87b4f82-1e11-4e37-e6d5-754c611f9cc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Graduate    2209\n",
              "Dropout     1421\n",
              "Enrolled     794\n",
              "Name: Target, dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['Target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrolQem-TV34",
        "outputId": "bacd12e5-bbe9-4863-912f-d8c57c23e42b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4424, 36)\n",
            "(4424, 1)\n"
          ]
        }
      ],
      "source": [
        "#Changing pandas dataframe to numpy array\n",
        "X = dataset.iloc[:,:36].values\n",
        "y = dataset.iloc[:,36:37].values\n",
        "y[10:40]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KlGwVDaATWqX"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "import math\n",
        "\n",
        "bordersmote = SMOTEENN()\n",
        "X, y = SMOTEENN().fit_resample(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LjzwqovUI80",
        "outputId": "841e1033-a2f5-4fdd-f979-852106897075"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['Dropout', 'Enrolled', 'Graduate'], dtype=object),\n",
              " array([1010, 1384,  730], dtype=int64))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique = np.unique(y, return_counts = True)\n",
        "unique\n",
        "# (array(['Dropout', 'Enrolled', 'Graduate'], dtype=object),\n",
        "# array([1020, 1416,  739], dtype=int64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One - Hot Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYJucrgfTayV",
        "outputId": "354fa819-1881-4224-e872-27d7c4163733"
      },
      "outputs": [],
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "encoded_Y = encoder.transform(y)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "# dummy_y[10:40]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DXMxCBmrTb7t"
      },
      "outputs": [],
      "source": [
        "#Normalizing the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "poly_features = PolynomialFeatures(degree = 2, include_bias = False)\n",
        "X = poly_features.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zNTX22OkTnnA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y4Uk8Yh7TpU3"
      },
      "outputs": [],
      "source": [
        "#Dependencies\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "# Neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 36, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units = 3, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cgYoymXmTuiE"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-c-Ns3ZTwAU",
        "outputId": "bc00ef59-d064-4d2c-e141-b8dfa3521921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "88/88 [==============================] - 7s 24ms/step - loss: 0.8740 - accuracy: 0.6379 - val_loss: 0.6061 - val_accuracy: 0.7284\n",
            "Epoch 2/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.5236 - accuracy: 0.7983 - val_loss: 0.5031 - val_accuracy: 0.8083\n",
            "Epoch 3/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.3704 - accuracy: 0.8591 - val_loss: 0.4204 - val_accuracy: 0.8307\n",
            "Epoch 4/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.2944 - accuracy: 0.8876 - val_loss: 0.4097 - val_accuracy: 0.8626\n",
            "Epoch 5/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.2631 - accuracy: 0.9093 - val_loss: 0.3732 - val_accuracy: 0.8594\n",
            "Epoch 6/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.2197 - accuracy: 0.9260 - val_loss: 0.4029 - val_accuracy: 0.8818\n",
            "Epoch 7/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.1917 - accuracy: 0.9306 - val_loss: 0.4086 - val_accuracy: 0.8754\n",
            "Epoch 8/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.1754 - accuracy: 0.9409 - val_loss: 0.3309 - val_accuracy: 0.8882\n",
            "Epoch 9/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.1474 - accuracy: 0.9466 - val_loss: 0.4076 - val_accuracy: 0.8978\n",
            "Epoch 10/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.1420 - accuracy: 0.9545 - val_loss: 0.3729 - val_accuracy: 0.8914\n",
            "Epoch 11/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.1333 - accuracy: 0.9523 - val_loss: 0.3281 - val_accuracy: 0.8914\n",
            "Epoch 12/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.1350 - accuracy: 0.9580 - val_loss: 0.3730 - val_accuracy: 0.8978\n",
            "Epoch 13/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.1321 - accuracy: 0.9591 - val_loss: 0.2891 - val_accuracy: 0.9137\n",
            "Epoch 14/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.1089 - accuracy: 0.9602 - val_loss: 0.3312 - val_accuracy: 0.9201\n",
            "Epoch 15/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.1027 - accuracy: 0.9648 - val_loss: 0.4081 - val_accuracy: 0.9010\n",
            "Epoch 16/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.1025 - accuracy: 0.9683 - val_loss: 0.3072 - val_accuracy: 0.9073\n",
            "Epoch 17/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0808 - accuracy: 0.9726 - val_loss: 0.3871 - val_accuracy: 0.8914\n",
            "Epoch 18/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0798 - accuracy: 0.9723 - val_loss: 0.4044 - val_accuracy: 0.9073\n",
            "Epoch 19/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0755 - accuracy: 0.9772 - val_loss: 0.3210 - val_accuracy: 0.9233\n",
            "Epoch 20/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0842 - accuracy: 0.9715 - val_loss: 0.3436 - val_accuracy: 0.9169\n",
            "Epoch 21/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0593 - accuracy: 0.9772 - val_loss: 0.4447 - val_accuracy: 0.9105\n",
            "Epoch 22/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0745 - accuracy: 0.9726 - val_loss: 0.3446 - val_accuracy: 0.9233\n",
            "Epoch 23/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0806 - accuracy: 0.9719 - val_loss: 0.3236 - val_accuracy: 0.9297\n",
            "Epoch 24/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0866 - accuracy: 0.9744 - val_loss: 0.4115 - val_accuracy: 0.9169\n",
            "Epoch 25/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0582 - accuracy: 0.9819 - val_loss: 0.3156 - val_accuracy: 0.9361\n",
            "Epoch 26/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0716 - accuracy: 0.9808 - val_loss: 0.4878 - val_accuracy: 0.9201\n",
            "Epoch 27/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0568 - accuracy: 0.9836 - val_loss: 0.4630 - val_accuracy: 0.9265\n",
            "Epoch 28/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0640 - accuracy: 0.9751 - val_loss: 0.4290 - val_accuracy: 0.9265\n",
            "Epoch 29/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0767 - accuracy: 0.9801 - val_loss: 0.4653 - val_accuracy: 0.9329\n",
            "Epoch 30/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0598 - accuracy: 0.9811 - val_loss: 0.5307 - val_accuracy: 0.9329\n",
            "Epoch 31/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0835 - accuracy: 0.9783 - val_loss: 0.4915 - val_accuracy: 0.9265\n",
            "Epoch 32/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0488 - accuracy: 0.9851 - val_loss: 0.6054 - val_accuracy: 0.9265\n",
            "Epoch 33/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0474 - accuracy: 0.9858 - val_loss: 0.7015 - val_accuracy: 0.9265\n",
            "Epoch 34/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0480 - accuracy: 0.9879 - val_loss: 0.6123 - val_accuracy: 0.9201\n",
            "Epoch 35/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0698 - accuracy: 0.9779 - val_loss: 0.5202 - val_accuracy: 0.9297\n",
            "Epoch 36/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0612 - accuracy: 0.9826 - val_loss: 0.4850 - val_accuracy: 0.9297\n",
            "Epoch 37/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 0.6119 - val_accuracy: 0.9233\n",
            "Epoch 38/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0520 - accuracy: 0.9840 - val_loss: 0.5253 - val_accuracy: 0.9169\n",
            "Epoch 39/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 0.5497 - val_accuracy: 0.9361\n",
            "Epoch 40/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0582 - accuracy: 0.9833 - val_loss: 0.6720 - val_accuracy: 0.9042\n",
            "Epoch 41/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0747 - accuracy: 0.9826 - val_loss: 0.5253 - val_accuracy: 0.9265\n",
            "Epoch 42/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0469 - accuracy: 0.9883 - val_loss: 0.4894 - val_accuracy: 0.9297\n",
            "Epoch 43/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0414 - accuracy: 0.9879 - val_loss: 0.5531 - val_accuracy: 0.9361\n",
            "Epoch 44/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0460 - accuracy: 0.9872 - val_loss: 0.5028 - val_accuracy: 0.9329\n",
            "Epoch 45/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 0.6233 - val_accuracy: 0.9297\n",
            "Epoch 46/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0513 - accuracy: 0.9868 - val_loss: 0.5060 - val_accuracy: 0.9425\n",
            "Epoch 47/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0507 - accuracy: 0.9904 - val_loss: 0.7912 - val_accuracy: 0.9233\n",
            "Epoch 48/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0563 - accuracy: 0.9861 - val_loss: 0.4329 - val_accuracy: 0.9265\n",
            "Epoch 49/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0589 - accuracy: 0.9826 - val_loss: 0.3833 - val_accuracy: 0.9457\n",
            "Epoch 50/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0364 - accuracy: 0.9879 - val_loss: 0.5711 - val_accuracy: 0.9201\n",
            "Epoch 51/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0431 - accuracy: 0.9886 - val_loss: 0.6661 - val_accuracy: 0.9201\n",
            "Epoch 52/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0463 - accuracy: 0.9861 - val_loss: 0.5152 - val_accuracy: 0.9105\n",
            "Epoch 53/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0674 - accuracy: 0.9836 - val_loss: 0.6382 - val_accuracy: 0.9297\n",
            "Epoch 54/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0470 - accuracy: 0.9893 - val_loss: 0.6824 - val_accuracy: 0.9233\n",
            "Epoch 55/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0437 - accuracy: 0.9883 - val_loss: 0.5945 - val_accuracy: 0.9361\n",
            "Epoch 56/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0560 - accuracy: 0.9847 - val_loss: 0.5793 - val_accuracy: 0.9169\n",
            "Epoch 57/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0531 - accuracy: 0.9861 - val_loss: 0.6299 - val_accuracy: 0.9201\n",
            "Epoch 58/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0505 - accuracy: 0.9890 - val_loss: 0.6353 - val_accuracy: 0.9393\n",
            "Epoch 59/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0311 - accuracy: 0.9929 - val_loss: 0.9619 - val_accuracy: 0.9329\n",
            "Epoch 60/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0427 - accuracy: 0.9908 - val_loss: 0.5919 - val_accuracy: 0.9425\n",
            "Epoch 61/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0417 - accuracy: 0.9893 - val_loss: 0.7715 - val_accuracy: 0.9233\n",
            "Epoch 62/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0470 - accuracy: 0.9865 - val_loss: 0.6675 - val_accuracy: 0.9105\n",
            "Epoch 63/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0482 - accuracy: 0.9875 - val_loss: 0.5275 - val_accuracy: 0.9233\n",
            "Epoch 64/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.4961 - val_accuracy: 0.9425\n",
            "Epoch 65/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 1.0650 - val_accuracy: 0.9361\n",
            "Epoch 66/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0591 - accuracy: 0.9868 - val_loss: 0.5407 - val_accuracy: 0.9457\n",
            "Epoch 67/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0413 - accuracy: 0.9875 - val_loss: 0.4709 - val_accuracy: 0.9361\n",
            "Epoch 68/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 0.7046 - val_accuracy: 0.9233\n",
            "Epoch 69/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0488 - accuracy: 0.9872 - val_loss: 0.6719 - val_accuracy: 0.9297\n",
            "Epoch 70/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.7732 - val_accuracy: 0.9329\n",
            "Epoch 71/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0335 - accuracy: 0.9893 - val_loss: 0.7175 - val_accuracy: 0.9233\n",
            "Epoch 72/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0327 - accuracy: 0.9883 - val_loss: 0.6542 - val_accuracy: 0.9265\n",
            "Epoch 73/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0230 - accuracy: 0.9911 - val_loss: 0.7821 - val_accuracy: 0.9265\n",
            "Epoch 74/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0379 - accuracy: 0.9886 - val_loss: 0.7425 - val_accuracy: 0.9329\n",
            "Epoch 75/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0255 - accuracy: 0.9929 - val_loss: 0.9895 - val_accuracy: 0.9361\n",
            "Epoch 76/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0381 - accuracy: 0.9890 - val_loss: 0.6672 - val_accuracy: 0.9137\n",
            "Epoch 77/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.8814 - val_accuracy: 0.9233\n",
            "Epoch 78/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0288 - accuracy: 0.9943 - val_loss: 0.8846 - val_accuracy: 0.9265\n",
            "Epoch 79/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0224 - accuracy: 0.9943 - val_loss: 0.8219 - val_accuracy: 0.9233\n",
            "Epoch 80/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0283 - accuracy: 0.9936 - val_loss: 0.8184 - val_accuracy: 0.9265\n",
            "Epoch 81/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0294 - accuracy: 0.9893 - val_loss: 1.0411 - val_accuracy: 0.9073\n",
            "Epoch 82/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0411 - accuracy: 0.9922 - val_loss: 1.0358 - val_accuracy: 0.9105\n",
            "Epoch 83/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0793 - accuracy: 0.9883 - val_loss: 0.8226 - val_accuracy: 0.9201\n",
            "Epoch 84/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0426 - accuracy: 0.9879 - val_loss: 0.6821 - val_accuracy: 0.9329\n",
            "Epoch 85/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0196 - accuracy: 0.9947 - val_loss: 1.1247 - val_accuracy: 0.9233\n",
            "Epoch 86/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0511 - accuracy: 0.9861 - val_loss: 0.9036 - val_accuracy: 0.9137\n",
            "Epoch 87/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0422 - accuracy: 0.9879 - val_loss: 0.8053 - val_accuracy: 0.9265\n",
            "Epoch 88/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0468 - accuracy: 0.9865 - val_loss: 0.8434 - val_accuracy: 0.9233\n",
            "Epoch 89/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0505 - accuracy: 0.9840 - val_loss: 0.8681 - val_accuracy: 0.9233\n",
            "Epoch 90/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.9108 - val_accuracy: 0.9201\n",
            "Epoch 91/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0317 - accuracy: 0.9911 - val_loss: 1.0718 - val_accuracy: 0.9201\n",
            "Epoch 92/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0504 - accuracy: 0.9890 - val_loss: 1.1905 - val_accuracy: 0.9265\n",
            "Epoch 93/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0509 - accuracy: 0.9890 - val_loss: 0.8712 - val_accuracy: 0.9329\n",
            "Epoch 94/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0354 - accuracy: 0.9883 - val_loss: 1.1516 - val_accuracy: 0.9393\n",
            "Epoch 95/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0302 - accuracy: 0.9922 - val_loss: 1.0118 - val_accuracy: 0.9297\n",
            "Epoch 96/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0501 - accuracy: 0.9890 - val_loss: 0.8679 - val_accuracy: 0.9329\n",
            "Epoch 97/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0482 - accuracy: 0.9897 - val_loss: 0.6936 - val_accuracy: 0.9329\n",
            "Epoch 98/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0292 - accuracy: 0.9897 - val_loss: 1.1132 - val_accuracy: 0.9297\n",
            "Epoch 99/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0339 - accuracy: 0.9908 - val_loss: 1.0076 - val_accuracy: 0.9393\n",
            "Epoch 100/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 1.5856 - val_accuracy: 0.9361\n",
            "Epoch 101/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0304 - accuracy: 0.9932 - val_loss: 0.9712 - val_accuracy: 0.9361\n",
            "Epoch 102/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0295 - accuracy: 0.9918 - val_loss: 1.1854 - val_accuracy: 0.9329\n",
            "Epoch 103/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0338 - accuracy: 0.9925 - val_loss: 0.7478 - val_accuracy: 0.9265\n",
            "Epoch 104/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 1.1197 - val_accuracy: 0.9361\n",
            "Epoch 105/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.9610 - val_accuracy: 0.9329\n",
            "Epoch 106/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0321 - accuracy: 0.9911 - val_loss: 1.1990 - val_accuracy: 0.9233\n",
            "Epoch 107/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0399 - accuracy: 0.9883 - val_loss: 1.1129 - val_accuracy: 0.9265\n",
            "Epoch 108/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0690 - accuracy: 0.9872 - val_loss: 1.4213 - val_accuracy: 0.9233\n",
            "Epoch 109/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0505 - accuracy: 0.9865 - val_loss: 1.3717 - val_accuracy: 0.9233\n",
            "Epoch 110/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0194 - accuracy: 0.9932 - val_loss: 1.5801 - val_accuracy: 0.9137\n",
            "Epoch 111/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0530 - accuracy: 0.9897 - val_loss: 1.4622 - val_accuracy: 0.9233\n",
            "Epoch 112/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0312 - accuracy: 0.9918 - val_loss: 1.4704 - val_accuracy: 0.9361\n",
            "Epoch 113/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0432 - accuracy: 0.9911 - val_loss: 1.1385 - val_accuracy: 0.9393\n",
            "Epoch 114/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0294 - accuracy: 0.9932 - val_loss: 0.9743 - val_accuracy: 0.9393\n",
            "Epoch 115/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0463 - accuracy: 0.9900 - val_loss: 0.7435 - val_accuracy: 0.9297\n",
            "Epoch 116/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0313 - accuracy: 0.9911 - val_loss: 1.0295 - val_accuracy: 0.9361\n",
            "Epoch 117/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0271 - accuracy: 0.9929 - val_loss: 0.8529 - val_accuracy: 0.9329\n",
            "Epoch 118/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0221 - accuracy: 0.9947 - val_loss: 1.0233 - val_accuracy: 0.9265\n",
            "Epoch 119/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0422 - accuracy: 0.9900 - val_loss: 0.9218 - val_accuracy: 0.9297\n",
            "Epoch 120/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0557 - accuracy: 0.9908 - val_loss: 0.4422 - val_accuracy: 0.9361\n",
            "Epoch 121/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0439 - accuracy: 0.9922 - val_loss: 0.6039 - val_accuracy: 0.9361\n",
            "Epoch 122/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0522 - accuracy: 0.9893 - val_loss: 0.9267 - val_accuracy: 0.9297\n",
            "Epoch 123/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0270 - accuracy: 0.9947 - val_loss: 1.3328 - val_accuracy: 0.9169\n",
            "Epoch 124/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0504 - accuracy: 0.9915 - val_loss: 0.6401 - val_accuracy: 0.9297\n",
            "Epoch 125/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0390 - accuracy: 0.9918 - val_loss: 0.9485 - val_accuracy: 0.9265\n",
            "Epoch 126/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0281 - accuracy: 0.9925 - val_loss: 1.1562 - val_accuracy: 0.9329\n",
            "Epoch 127/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 1.1092 - val_accuracy: 0.9233\n",
            "Epoch 128/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0347 - accuracy: 0.9940 - val_loss: 1.3444 - val_accuracy: 0.9265\n",
            "Epoch 129/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0366 - accuracy: 0.9904 - val_loss: 1.2935 - val_accuracy: 0.9105\n",
            "Epoch 130/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0334 - accuracy: 0.9904 - val_loss: 0.9032 - val_accuracy: 0.9233\n",
            "Epoch 131/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 1.0573 - val_accuracy: 0.9393\n",
            "Epoch 132/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0300 - accuracy: 0.9961 - val_loss: 1.3359 - val_accuracy: 0.9265\n",
            "Epoch 133/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0261 - accuracy: 0.9943 - val_loss: 1.5134 - val_accuracy: 0.9233\n",
            "Epoch 134/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0353 - accuracy: 0.9925 - val_loss: 0.7936 - val_accuracy: 0.9329\n",
            "Epoch 135/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0307 - accuracy: 0.9925 - val_loss: 1.1200 - val_accuracy: 0.9265\n",
            "Epoch 136/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0274 - accuracy: 0.9936 - val_loss: 1.0380 - val_accuracy: 0.9393\n",
            "Epoch 137/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0360 - accuracy: 0.9932 - val_loss: 0.7583 - val_accuracy: 0.9297\n",
            "Epoch 138/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0344 - accuracy: 0.9918 - val_loss: 0.8143 - val_accuracy: 0.9297\n",
            "Epoch 139/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0341 - accuracy: 0.9932 - val_loss: 0.7329 - val_accuracy: 0.9393\n",
            "Epoch 140/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0270 - accuracy: 0.9947 - val_loss: 0.8184 - val_accuracy: 0.9361\n",
            "Epoch 141/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 1.0597 - val_accuracy: 0.9361\n",
            "Epoch 142/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0356 - accuracy: 0.9908 - val_loss: 1.3040 - val_accuracy: 0.9361\n",
            "Epoch 143/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 0.6732 - val_accuracy: 0.9297\n",
            "Epoch 144/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0345 - accuracy: 0.9925 - val_loss: 0.9113 - val_accuracy: 0.9393\n",
            "Epoch 145/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0383 - accuracy: 0.9908 - val_loss: 0.6071 - val_accuracy: 0.9361\n",
            "Epoch 146/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0321 - accuracy: 0.9911 - val_loss: 1.3348 - val_accuracy: 0.9329\n",
            "Epoch 147/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 1.2036 - val_accuracy: 0.9265\n",
            "Epoch 148/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 1.0814 - val_accuracy: 0.9265\n",
            "Epoch 149/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 1.4982 - val_accuracy: 0.9233\n",
            "Epoch 150/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0291 - accuracy: 0.9936 - val_loss: 1.0974 - val_accuracy: 0.9201\n",
            "Epoch 151/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 1.1294 - val_accuracy: 0.9297\n",
            "Epoch 152/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 1.1763 - val_accuracy: 0.9329\n",
            "Epoch 153/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0252 - accuracy: 0.9900 - val_loss: 1.4021 - val_accuracy: 0.9361\n",
            "Epoch 154/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0317 - accuracy: 0.9925 - val_loss: 1.3302 - val_accuracy: 0.9297\n",
            "Epoch 155/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0231 - accuracy: 0.9925 - val_loss: 1.3474 - val_accuracy: 0.9329\n",
            "Epoch 156/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0386 - accuracy: 0.9908 - val_loss: 1.3068 - val_accuracy: 0.9201\n",
            "Epoch 157/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0409 - accuracy: 0.9911 - val_loss: 0.8939 - val_accuracy: 0.9361\n",
            "Epoch 158/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0288 - accuracy: 0.9940 - val_loss: 0.8399 - val_accuracy: 0.9297\n",
            "Epoch 159/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 1.0973 - val_accuracy: 0.9297\n",
            "Epoch 160/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 0.9177 - val_accuracy: 0.9265\n",
            "Epoch 161/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 1.2128 - val_accuracy: 0.9297\n",
            "Epoch 162/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0291 - accuracy: 0.9925 - val_loss: 0.9798 - val_accuracy: 0.9265\n",
            "Epoch 163/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0307 - accuracy: 0.9925 - val_loss: 0.8285 - val_accuracy: 0.9393\n",
            "Epoch 164/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0218 - accuracy: 0.9918 - val_loss: 1.2241 - val_accuracy: 0.9265\n",
            "Epoch 165/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0285 - accuracy: 0.9911 - val_loss: 1.1629 - val_accuracy: 0.9201\n",
            "Epoch 166/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0436 - accuracy: 0.9890 - val_loss: 1.3369 - val_accuracy: 0.9297\n",
            "Epoch 167/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.3560 - accuracy: 0.9883 - val_loss: 0.8497 - val_accuracy: 0.9201\n",
            "Epoch 168/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0399 - accuracy: 0.9900 - val_loss: 1.0861 - val_accuracy: 0.9265\n",
            "Epoch 169/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0283 - accuracy: 0.9929 - val_loss: 1.1565 - val_accuracy: 0.9265\n",
            "Epoch 170/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0296 - accuracy: 0.9922 - val_loss: 0.9354 - val_accuracy: 0.9233\n",
            "Epoch 171/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0312 - accuracy: 0.9904 - val_loss: 1.0402 - val_accuracy: 0.9265\n",
            "Epoch 172/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 0.9901 - val_accuracy: 0.9297\n",
            "Epoch 173/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0243 - accuracy: 0.9936 - val_loss: 1.2612 - val_accuracy: 0.9329\n",
            "Epoch 174/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0693 - accuracy: 0.9932 - val_loss: 1.3319 - val_accuracy: 0.9297\n",
            "Epoch 175/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0541 - accuracy: 0.9883 - val_loss: 1.0506 - val_accuracy: 0.9233\n",
            "Epoch 176/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 0.9167 - val_accuracy: 0.9297\n",
            "Epoch 177/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0679 - accuracy: 0.9925 - val_loss: 1.0862 - val_accuracy: 0.9169\n",
            "Epoch 178/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0698 - accuracy: 0.9900 - val_loss: 0.6941 - val_accuracy: 0.9201\n",
            "Epoch 179/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0255 - accuracy: 0.9950 - val_loss: 1.4153 - val_accuracy: 0.9137\n",
            "Epoch 180/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0246 - accuracy: 0.9950 - val_loss: 1.1648 - val_accuracy: 0.9297\n",
            "Epoch 181/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0558 - accuracy: 0.9904 - val_loss: 2.0507 - val_accuracy: 0.9169\n",
            "Epoch 182/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0451 - accuracy: 0.9886 - val_loss: 1.4071 - val_accuracy: 0.9137\n",
            "Epoch 183/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 1.2602 - val_accuracy: 0.9169\n",
            "Epoch 184/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0417 - accuracy: 0.9900 - val_loss: 0.8727 - val_accuracy: 0.9201\n",
            "Epoch 185/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0277 - accuracy: 0.9936 - val_loss: 0.8357 - val_accuracy: 0.9201\n",
            "Epoch 186/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0243 - accuracy: 0.9947 - val_loss: 1.5132 - val_accuracy: 0.9105\n",
            "Epoch 187/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0214 - accuracy: 0.9918 - val_loss: 1.1059 - val_accuracy: 0.9233\n",
            "Epoch 188/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 1.3768 - val_accuracy: 0.9297\n",
            "Epoch 189/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 1.7297 - val_accuracy: 0.9361\n",
            "Epoch 190/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0331 - accuracy: 0.9929 - val_loss: 1.4998 - val_accuracy: 0.9329\n",
            "Epoch 191/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0248 - accuracy: 0.9925 - val_loss: 1.4037 - val_accuracy: 0.9393\n",
            "Epoch 192/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0201 - accuracy: 0.9950 - val_loss: 1.5557 - val_accuracy: 0.9361\n",
            "Epoch 193/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 1.2563 - val_accuracy: 0.9297\n",
            "Epoch 194/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0228 - accuracy: 0.9954 - val_loss: 0.9369 - val_accuracy: 0.9393\n",
            "Epoch 195/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0263 - accuracy: 0.9940 - val_loss: 1.0420 - val_accuracy: 0.9329\n",
            "Epoch 196/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0278 - accuracy: 0.9932 - val_loss: 1.1512 - val_accuracy: 0.9361\n",
            "Epoch 197/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0378 - accuracy: 0.9918 - val_loss: 1.0153 - val_accuracy: 0.9233\n",
            "Epoch 198/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 1.3587 - val_accuracy: 0.9265\n",
            "Epoch 199/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 1.6861 - val_accuracy: 0.9233\n",
            "Epoch 200/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0954 - accuracy: 0.9936 - val_loss: 1.6926 - val_accuracy: 0.9265\n",
            "Epoch 201/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0224 - accuracy: 0.9947 - val_loss: 1.7940 - val_accuracy: 0.9297\n",
            "Epoch 202/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0426 - accuracy: 0.9918 - val_loss: 1.4221 - val_accuracy: 0.9329\n",
            "Epoch 203/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0343 - accuracy: 0.9908 - val_loss: 1.4096 - val_accuracy: 0.9297\n",
            "Epoch 204/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0308 - accuracy: 0.9918 - val_loss: 1.3786 - val_accuracy: 0.9393\n",
            "Epoch 205/300\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 1.7812 - val_accuracy: 0.9361\n",
            "Epoch 206/300\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 1.6684 - val_accuracy: 0.9425\n",
            "Epoch 207/300\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0260 - accuracy: 0.9932 - val_loss: 1.6080 - val_accuracy: 0.9329\n",
            "Epoch 208/300\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0272 - accuracy: 0.9925 - val_loss: 2.3181 - val_accuracy: 0.9105\n",
            "Epoch 209/300\n",
            "88/88 [==============================] - 1s 14ms/step - loss: 0.0377 - accuracy: 0.9908 - val_loss: 1.8526 - val_accuracy: 0.9361\n",
            "Epoch 210/300\n",
            "88/88 [==============================] - 1s 13ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 2.0417 - val_accuracy: 0.9457\n",
            "Epoch 211/300\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0357 - accuracy: 0.9925 - val_loss: 1.8729 - val_accuracy: 0.9425\n",
            "Epoch 212/300\n",
            "88/88 [==============================] - 1s 14ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 1.3027 - val_accuracy: 0.9297\n",
            "Epoch 213/300\n",
            "88/88 [==============================] - 1s 14ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 1.6410 - val_accuracy: 0.9361\n",
            "Epoch 214/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0322 - accuracy: 0.9929 - val_loss: 1.6930 - val_accuracy: 0.9329\n",
            "Epoch 215/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0265 - accuracy: 0.9932 - val_loss: 0.9361 - val_accuracy: 0.9297\n",
            "Epoch 216/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0352 - accuracy: 0.9897 - val_loss: 1.1100 - val_accuracy: 0.9329\n",
            "Epoch 217/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 1.0259 - val_accuracy: 0.9329\n",
            "Epoch 218/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 1.3043 - val_accuracy: 0.9329\n",
            "Epoch 219/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0309 - accuracy: 0.9936 - val_loss: 1.0610 - val_accuracy: 0.9361\n",
            "Epoch 220/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 1.2552 - val_accuracy: 0.9297\n",
            "Epoch 221/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 1.4049 - val_accuracy: 0.9361\n",
            "Epoch 222/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0125 - accuracy: 0.9950 - val_loss: 1.5743 - val_accuracy: 0.9297\n",
            "Epoch 223/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 1.2760 - val_accuracy: 0.9361\n",
            "Epoch 224/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0473 - accuracy: 0.9893 - val_loss: 0.6901 - val_accuracy: 0.9329\n",
            "Epoch 225/300\n",
            "88/88 [==============================] - 2s 21ms/step - loss: 0.0465 - accuracy: 0.9897 - val_loss: 0.9504 - val_accuracy: 0.9425\n",
            "Epoch 226/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0252 - accuracy: 0.9940 - val_loss: 1.1208 - val_accuracy: 0.9457\n",
            "Epoch 227/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0257 - accuracy: 0.9950 - val_loss: 1.2736 - val_accuracy: 0.9457\n",
            "Epoch 228/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 1.2654 - val_accuracy: 0.9425\n",
            "Epoch 229/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 1.6947 - val_accuracy: 0.9361\n",
            "Epoch 230/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.9226 - val_accuracy: 0.9233\n",
            "Epoch 231/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0388 - accuracy: 0.9925 - val_loss: 1.2155 - val_accuracy: 0.9297\n",
            "Epoch 232/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 1.4777 - val_accuracy: 0.9265\n",
            "Epoch 233/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 1.8246 - val_accuracy: 0.9201\n",
            "Epoch 234/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 1.2623 - val_accuracy: 0.9329\n",
            "Epoch 235/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0241 - accuracy: 0.9947 - val_loss: 1.4762 - val_accuracy: 0.9297\n",
            "Epoch 236/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0222 - accuracy: 0.9918 - val_loss: 1.2044 - val_accuracy: 0.9329\n",
            "Epoch 237/300\n",
            "88/88 [==============================] - 2s 21ms/step - loss: 0.0263 - accuracy: 0.9943 - val_loss: 1.3006 - val_accuracy: 0.9361\n",
            "Epoch 238/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0201 - accuracy: 0.9957 - val_loss: 1.4182 - val_accuracy: 0.9265\n",
            "Epoch 239/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0239 - accuracy: 0.9947 - val_loss: 1.8922 - val_accuracy: 0.9233\n",
            "Epoch 240/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0436 - accuracy: 0.9890 - val_loss: 1.0427 - val_accuracy: 0.9393\n",
            "Epoch 241/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0267 - accuracy: 0.9918 - val_loss: 1.2619 - val_accuracy: 0.9265\n",
            "Epoch 242/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 1.4868 - val_accuracy: 0.9169\n",
            "Epoch 243/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 2.2100 - val_accuracy: 0.9265\n",
            "Epoch 244/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0338 - accuracy: 0.9922 - val_loss: 1.1132 - val_accuracy: 0.9361\n",
            "Epoch 245/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0303 - accuracy: 0.9936 - val_loss: 1.0376 - val_accuracy: 0.9265\n",
            "Epoch 246/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0208 - accuracy: 0.9961 - val_loss: 0.8941 - val_accuracy: 0.9329\n",
            "Epoch 247/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 1.0243 - val_accuracy: 0.9297\n",
            "Epoch 248/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 1.2678 - val_accuracy: 0.9233\n",
            "Epoch 249/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 1.2105 - val_accuracy: 0.9265\n",
            "Epoch 250/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.4403 - val_accuracy: 0.9233\n",
            "Epoch 251/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 1.2418 - val_accuracy: 0.9361\n",
            "Epoch 252/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0256 - accuracy: 0.9950 - val_loss: 1.7559 - val_accuracy: 0.9265\n",
            "Epoch 253/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0337 - accuracy: 0.9940 - val_loss: 1.3051 - val_accuracy: 0.9361\n",
            "Epoch 254/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 1.4466 - val_accuracy: 0.9265\n",
            "Epoch 255/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 1.9759 - val_accuracy: 0.9329\n",
            "Epoch 256/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0314 - accuracy: 0.9915 - val_loss: 1.3797 - val_accuracy: 0.9297\n",
            "Epoch 257/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 2.0324 - val_accuracy: 0.9297\n",
            "Epoch 258/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0385 - accuracy: 0.9925 - val_loss: 1.9182 - val_accuracy: 0.9233\n",
            "Epoch 259/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0859 - accuracy: 0.9925 - val_loss: 1.0344 - val_accuracy: 0.9265\n",
            "Epoch 260/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0256 - accuracy: 0.9936 - val_loss: 0.9638 - val_accuracy: 0.9297\n",
            "Epoch 261/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.8760 - val_accuracy: 0.9297\n",
            "Epoch 262/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0518 - accuracy: 0.9918 - val_loss: 1.1753 - val_accuracy: 0.9361\n",
            "Epoch 263/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0246 - accuracy: 0.9954 - val_loss: 1.3372 - val_accuracy: 0.9393\n",
            "Epoch 264/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0229 - accuracy: 0.9943 - val_loss: 1.6505 - val_accuracy: 0.9297\n",
            "Epoch 265/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0478 - accuracy: 0.9904 - val_loss: 0.7635 - val_accuracy: 0.9457\n",
            "Epoch 266/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.9624 - val_accuracy: 0.9457\n",
            "Epoch 267/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.9966 - val_accuracy: 0.9457\n",
            "Epoch 268/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0274 - accuracy: 0.9943 - val_loss: 1.1605 - val_accuracy: 0.9329\n",
            "Epoch 269/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0489 - accuracy: 0.9929 - val_loss: 1.2866 - val_accuracy: 0.9393\n",
            "Epoch 270/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0375 - accuracy: 0.9925 - val_loss: 1.2127 - val_accuracy: 0.9361\n",
            "Epoch 271/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0231 - accuracy: 0.9957 - val_loss: 0.9641 - val_accuracy: 0.9425\n",
            "Epoch 272/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0400 - accuracy: 0.9950 - val_loss: 1.3010 - val_accuracy: 0.9265\n",
            "Epoch 273/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0368 - accuracy: 0.9918 - val_loss: 1.1322 - val_accuracy: 0.9393\n",
            "Epoch 274/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 1.7654 - val_accuracy: 0.9425\n",
            "Epoch 275/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 1.7698 - val_accuracy: 0.9457\n",
            "Epoch 276/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 1.8350 - val_accuracy: 0.9425\n",
            "Epoch 277/300\n",
            "88/88 [==============================] - 1s 17ms/step - loss: 0.0219 - accuracy: 0.9961 - val_loss: 1.5390 - val_accuracy: 0.9361\n",
            "Epoch 278/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0398 - accuracy: 0.9915 - val_loss: 1.5887 - val_accuracy: 0.9201\n",
            "Epoch 279/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0220 - accuracy: 0.9947 - val_loss: 1.1570 - val_accuracy: 0.9521\n",
            "Epoch 280/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 1.6898 - val_accuracy: 0.9489\n",
            "Epoch 281/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 1.5281 - val_accuracy: 0.9521\n",
            "Epoch 282/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0096 - accuracy: 0.9961 - val_loss: 2.0474 - val_accuracy: 0.9329\n",
            "Epoch 283/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0217 - accuracy: 0.9968 - val_loss: 2.0869 - val_accuracy: 0.9425\n",
            "Epoch 284/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0243 - accuracy: 0.9950 - val_loss: 2.3453 - val_accuracy: 0.9457\n",
            "Epoch 285/300\n",
            "88/88 [==============================] - 2s 20ms/step - loss: 0.0244 - accuracy: 0.9932 - val_loss: 2.9153 - val_accuracy: 0.9169\n",
            "Epoch 286/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 2.8455 - val_accuracy: 0.9233\n",
            "Epoch 287/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0155 - accuracy: 0.9932 - val_loss: 2.1245 - val_accuracy: 0.9361\n",
            "Epoch 288/300\n",
            "88/88 [==============================] - 2s 21ms/step - loss: 0.0242 - accuracy: 0.9957 - val_loss: 1.5241 - val_accuracy: 0.9457\n",
            "Epoch 289/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0406 - accuracy: 0.9925 - val_loss: 0.9806 - val_accuracy: 0.9457\n",
            "Epoch 290/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 1.3749 - val_accuracy: 0.9457\n",
            "Epoch 291/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0356 - accuracy: 0.9932 - val_loss: 1.2021 - val_accuracy: 0.9425\n",
            "Epoch 292/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0214 - accuracy: 0.9957 - val_loss: 1.1318 - val_accuracy: 0.9489\n",
            "Epoch 293/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0095 - accuracy: 0.9975 - val_loss: 1.9881 - val_accuracy: 0.9393\n",
            "Epoch 294/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0495 - accuracy: 0.9936 - val_loss: 0.6894 - val_accuracy: 0.9329\n",
            "Epoch 295/300\n",
            "88/88 [==============================] - 2s 19ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 1.5376 - val_accuracy: 0.9393\n",
            "Epoch 296/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 1.3348 - val_accuracy: 0.9361\n",
            "Epoch 297/300\n",
            "88/88 [==============================] - 2s 18ms/step - loss: 0.0237 - accuracy: 0.9943 - val_loss: 1.5274 - val_accuracy: 0.9393\n",
            "Epoch 298/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0180 - accuracy: 0.9957 - val_loss: 1.6963 - val_accuracy: 0.9393\n",
            "Epoch 299/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0300 - accuracy: 0.9908 - val_loss: 1.8003 - val_accuracy: 0.9457\n",
            "Epoch 300/300\n",
            "88/88 [==============================] - 2s 17ms/step - loss: 0.0196 - accuracy: 0.9925 - val_loss: 2.3133 - val_accuracy: 0.9329\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs = 300, validation_data = (X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW_brfNH8IXk",
        "outputId": "0f149cc2-105f-447b-a283-7cb67cef131b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9520766735076904"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "M50U2tCv8P6e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('predict_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "later_model = load_model('predict_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "losses.plot()\n",
        "plt.savefig('losses.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Marital status                                       1.000000\n",
              "Application mode                                    17.000000\n",
              "Application order                                    1.000000\n",
              "Course                                            9853.000000\n",
              "Daytime/evening attendance                           1.000000\n",
              "Previous qualification                               1.000000\n",
              "Previous qualification (grade)                     125.000000\n",
              "Nacionality                                          1.000000\n",
              "Mother's qualification                              19.000000\n",
              "Father's qualification                              19.000000\n",
              "Mother's occupation                                  4.000000\n",
              "Father's occupation                                  7.000000\n",
              "Admission grade                                    128.500000\n",
              "Displaced                                            1.000000\n",
              "Educational special needs                            0.000000\n",
              "Debtor                                               0.000000\n",
              "Tuition fees up to date                              1.000000\n",
              "Gender                                               0.000000\n",
              "Scholarship holder                                   0.000000\n",
              "Age at enrollment                                   18.000000\n",
              "International                                        0.000000\n",
              "Curricular units 1st sem (credited)                  0.000000\n",
              "Curricular units 1st sem (enrolled)                  7.000000\n",
              "Curricular units 1st sem (evaluations)               9.000000\n",
              "Curricular units 1st sem (approved)                  6.000000\n",
              "Curricular units 1st sem (grade)                    11.500000\n",
              "Curricular units 1st sem (without evaluations)       0.000000\n",
              "Curricular units 2nd sem (credited)                  0.000000\n",
              "Curricular units 2nd sem (enrolled)                  7.000000\n",
              "Curricular units 2nd sem (evaluations)               8.000000\n",
              "Curricular units 2nd sem (approved)                  7.000000\n",
              "Curricular units 2nd sem (grade)                    12.714286\n",
              "Curricular units 2nd sem (without evaluations)       0.000000\n",
              "Unemployment rate                                   13.900000\n",
              "Inflation rate                                      -0.300000\n",
              "GDP                                                  0.790000\n",
              "Name: 1195, dtype: float64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "random.seed(87)\n",
        "random_ind = random.randint(0, len(dataset))\n",
        "\n",
        "new_student = dataset.drop('Target', axis = 1).iloc[random_ind]\n",
        "new_student"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.9329073482428115\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.90      0.93       101\n",
            "           1       0.93      0.95      0.94       135\n",
            "           2       0.92      0.95      0.94        77\n",
            "\n",
            "   micro avg       0.94      0.93      0.94       313\n",
            "   macro avg       0.94      0.93      0.94       313\n",
            "weighted avg       0.94      0.93      0.94       313\n",
            " samples avg       0.93      0.93      0.93       313\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy Score:', accuracy_score(y_test, predictions))\n",
        "print('\\n')\n",
        "print(classification_report(y_test, predictions))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Untitled2.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
