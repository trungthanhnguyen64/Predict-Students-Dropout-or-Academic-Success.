{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'boston_house_prices.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston    # 506 samples, 13 feature\n",
    "\n",
    "df = load_boston()\n",
    "x = df.data\n",
    "y = df.target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "       7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "       1.7800e+01, 3.9283e+02, 4.0300e+00])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearson's correlation feature selection for numeric input and numeric output\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature selection\n",
    "fs = SelectKBest(score_func = f_regression, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 10)\n"
     ]
    }
   ],
   "source": [
    "# apply feature selection\n",
    "x_selected = fs.fit_transform(x, y)\n",
    "print(x_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1,1), copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.fit_transform(x_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'scaler.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(x, y, test_size = 0.2, random_state = 87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data X train matrix (404, 10)\n",
      "Size of data Y train array (404,)\n",
      "Size of data X test matrix (102, 10)\n",
      "Size of data Y test array (102,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of data X train matrix %s\"  % str(train_X.shape))\n",
    "print(\"Size of data Y train array %s\"  % str(train_y.shape))\n",
    "print(\"Size of data X test matrix %s\"  % str(test_X.shape))\n",
    "print(\"Size of data Y test array %s\"  % str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_column_train = np.ones((train_X.shape[0], 1))\n",
    "train_X_new = np.append(one_column_train, train_X, axis = 1) # Add bias\n",
    "\n",
    "one_column_test = np.ones((test_X.shape[0], 1))\n",
    "test_X_new = np.append(one_column_test, test_X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data X train matrix (404, 11)\n",
      "Size of data Y train array (404,)\n",
      "Size of data X test matrix (102, 11)\n",
      "Size of data Y test array (102,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of data X train matrix %s\"  % str(train_X_new.shape))\n",
    "print(\"Size of data Y train array %s\"  % str(train_y.shape))\n",
    "print(\"Size of data X test matrix %s\"  % str(test_X_new.shape))\n",
    "print(\"Size of data Y test array %s\"  % str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_cost_vectorized(w, X, y):\n",
    "    '''\n",
    "    Evaluate the cost function in a vectorized manner for \n",
    "    inputs `X` and targets `t`, at weights `w` and `b`.\n",
    "    \n",
    "    X: dataset matrix has (m, n) dimension. \n",
    "    y: targets vector has (n, ) dimension.\n",
    "    w: weights vector has (n, ) dimension\n",
    "    b: a scalar bias.\n",
    "    \n",
    "    Return a scalar cost value of `w`, `b`.\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[0] # number of samples in dataset\n",
    "    w = np.array(w) # convert to numpy array\n",
    "    y_hat = np.dot(X, w) # hypothesis\n",
    "    \n",
    "    return np.sum((y_hat - y)**2)/(2*m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_grad_fn_vectorized(w, X, y):\n",
    "    '''\n",
    "    Given `w` - a current \"Guess\" of what our weights should be\n",
    "          `X` - matrix of shape (m, n + 1) of input features\n",
    "          `y` - target y values\n",
    "    Return gradient of each weight evaluated at the current value\n",
    "    '''\n",
    "    \n",
    "    #TODO: Complete the below followed the above expressions\n",
    "    m, n = X.shape\n",
    "    y_hat = np.dot(X, w)\n",
    "    grad_w = np.dot(X.T, y_hat - y)/m\n",
    "    \n",
    "    return grad_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_solve_via_gradient_descent(X, y, print_every=5000,\n",
    "                                  niter=100000, alpha=0.005):\n",
    "    '''\n",
    "    Given `X` - matrix of shape (m, n+1) of input features\n",
    "          `y` - target y values\n",
    "    Solves for linear regression weights.\n",
    "    Return weights after `niter` iterations.\n",
    "    '''\n",
    "\n",
    "    m, n = X.shape\n",
    "    J_all = []\n",
    "\n",
    "    # initialize all the weights to zeros\n",
    "    w = np.zeros((n,))\n",
    "    for k in range(niter):\n",
    "        \n",
    "        dw = np_grad_fn_vectorized(w, X, y) \n",
    "        w = w - alpha*dw\n",
    "        J_all.append(np_cost_vectorized(w, X, y))\n",
    "\n",
    "        if k % print_every == 0:\n",
    "            print('Weight after %d iteration: %s' % (k, str(w)))\n",
    "    return w, J_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight after 0 iteration: [ 0.11068564 -0.10490539 -0.07774577 -0.03496202 -0.04104283  0.01160501\n",
      "  0.02854537 -0.0386059  -0.02836748  0.01806617 -0.05628449]\n",
      "Weight after 5000 iteration: [ 10.45902987  -7.83098211  -0.55359742  -0.60659697  -1.99213726\n",
      "   8.89099703   1.48677296   2.76026889  -1.11241789  -5.08984604\n",
      " -10.7935953 ]\n"
     ]
    }
   ],
   "source": [
    "opt_w, J_all = np_solve_via_gradient_descent(train_X_new, train_y, niter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost(J_all, num_niter):\n",
    "\tplt.xlabel('Niter')\n",
    "\tplt.ylabel('Cost')\n",
    "\tplt.plot(num_niter, J_all, 'm', linewidth = \"5\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_niter = []\n",
    "jplot = []\n",
    "count = 0\n",
    "for i in range(len(J_all)):\n",
    "\tjplot.append(J_all[i])\n",
    "\tn_niter.append(count)\n",
    "\tcount += 1\n",
    "jplot = np.array(jplot)\n",
    "n_niter = np.array(n_niter)\n",
    "plot_cost(jplot, n_niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost: 12.449672904641005\n"
     ]
    }
   ],
   "source": [
    "print(\"Training cost:\", np_cost_vectorized(opt_w, train_X_new, train_y)) # Training cost: 12.449672904641005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing cost: 14.910843981138196\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing cost:\", np_cost_vectorized(opt_w, test_X_new, test_y)) # Testing cost: 14.910843981138196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(theta, x):\n",
    "\tx_arr = np.array(x)\n",
    "\tx_rs = x_arr.reshape(1, -1)\n",
    "\tscaler = joblib.load('scaler.joblib')\n",
    "\tx_norm = scaler.transform(x_rs)\n",
    "\tone_column = np.ones((x_norm.shape[0], 1))\n",
    "\tx_test = np.append(one_column, x_norm, axis = 1) # Add bias\n",
    "\n",
    "\ty = np.dot(x_test, theta)\n",
    "\tprint(\"Price of house: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = [2.35697744e-04, 0.00000000e+00, 2.42302053e-01, 1.72839506e-01,\n",
    "       6.94385898e-01, 5.99382080e-01, 4.34782609e-02, 1.04961832e-01,\n",
    "       5.53191489e-01, 6.34657837e-02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price of house:  [29.72654451]\n"
     ]
    }
   ],
   "source": [
    "test(opt_w, xtest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
